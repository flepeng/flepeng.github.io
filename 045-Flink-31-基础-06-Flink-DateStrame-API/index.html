

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2488174175014870" crossorigin="anonymous"></script><!-- google 广告 -->
  <meta name="google-site-verification" content="40lMg4eqLLbXoDcpN3h-cEnfmselbQ8tUzNvuC0IRIs" /><!-- google 站点认证 -->
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Lepeng">
  <meta name="keywords" content="">
  
    <meta name="description" content="Flink 官网主页地址：https:&#x2F;&#x2F;flink.apache.org  Flink 官方中文地址：https:&#x2F;&#x2F;nightlies.apache.org&#x2F;flink&#x2F;flink-docs-stable&#x2F;zh&#x2F;  DataStream APIDataStream API 是 Flink 核心层 API。一个 Flink 程序，其实就是对 DataStream 的各种转换。具体来说，代码">
<meta property="og:type" content="article">
<meta property="og:title" content="06-Flink DateStrame API">
<meta property="og:url" content="https://flepeng.github.io/045-Flink-31-%E5%9F%BA%E7%A1%80-06-Flink-DateStrame-API/index.html">
<meta property="og:site_name" content="Lepeng">
<meta property="og:description" content="Flink 官网主页地址：https:&#x2F;&#x2F;flink.apache.org  Flink 官方中文地址：https:&#x2F;&#x2F;nightlies.apache.org&#x2F;flink&#x2F;flink-docs-stable&#x2F;zh&#x2F;  DataStream APIDataStream API 是 Flink 核心层 API。一个 Flink 程序，其实就是对 DataStream 的各种转换。具体来说，代码">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_10-14-37.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_10-14-38.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_10-14-39.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_10-14-40.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_10-14-42.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_10-14-41.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_10-14-43.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/6865.jpg">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/20230608125535.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_16-47-17.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_16-47-18.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_16-59-13.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_16-59-31.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_16-59-32.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_16-59-33.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2024-06-06_22-54-26.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_20-57-21.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_20-57-22.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_21-01-40.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_21-02-50.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_21-05-20.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_21-12-12.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_21-12-13.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_21-12-14.png">
<meta property="og:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_21-12-15.png">
<meta property="article:published_time" content="2021-03-07T16:00:00.000Z">
<meta property="article:modified_time" content="2025-04-03T10:25:30.403Z">
<meta property="article:author" content="Feng Lepeng">
<meta property="article:tag" content="Flink">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://flepeng.github.io/img/flink/00/Snipaste_2023-06-07_10-14-37.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>06-Flink DateStrame API - Lepeng</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"flepeng.github.io","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":"f3d259b9efd9ce8655c180fd01bf0045","google":{"measurement_id":"G-LFTE4C7W3W"},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  
    <!-- Baidu Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?f3d259b9efd9ce8655c180fd01bf0045";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
      }
    </script>
  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=G-LFTE4C7W3W", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', 'G-LFTE4C7W3W');
        });
      }
    </script>
  

  

  

  

  



  
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Lepeng 的 blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="06-Flink DateStrame API"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2021-03-08 00:00" pubdate>
          2021年3月8日 凌晨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          13k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          107 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">06-Flink DateStrame API</h1>
            
            
              <div class="markdown-body">
                
                <blockquote>
<p>  Flink 官网主页地址：<a href="https://flink.apache.org/" target="_blank" rel="noopener">https://flink.apache.org</a><br>  Flink 官方中文地址：<a href="https://nightlies.apache.org/flink/flink-docs-stable/zh/" target="_blank" rel="noopener">https://nightlies.apache.org/flink/flink-docs-stable/zh/</a></p>
</blockquote>
<h1 id="DataStream-API"><a href="#DataStream-API" class="headerlink" title="DataStream API"></a>DataStream API</h1><p>DataStream API 是 Flink 核心层 API。一个 Flink 程序，其实就是对 DataStream 的各种转换。具体来说，代码基本上都由以下几部分构成：</p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_10-14-37.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="1、执行环境（Execution-Environment）"><a href="#1、执行环境（Execution-Environment）" class="headerlink" title="1、执行环境（Execution Environment）"></a>1、执行环境（Execution Environment）</h1><p>Flink 程序可以在各种上下文环境中运行；我们可以在本地 JVM 中执行程序，也可以提交到远程集群上运行。  </p>
<p>不同的环境，代码提交运行的过程会有所不同。这就要求我们在提交作业执行计算时，首先必须获取当前 Flink 的运行环境，从而建立起与 Flink 框架之间的联系。</p>
<h2 id="1-1、创建执行环境"><a href="#1-1、创建执行环境" class="headerlink" title="1.1、创建执行环境"></a>1.1、创建执行环境</h2><p>我们要获取的执行环境，是 <code>StreamExecutionEnviroment</code> 类的对象，这是所有 Flink 程序的基础。在代码中成绩执行环境的方式，就是调用这个类的静态方法，具体有一下三种。  </p>
<ol>
<li><p><code>getExecutionEnviroment</code></p>
<p>最简单的方式，就是直接调用 <code>getExecutionEnvironment</code> 方法。它会根据当前运行的上下文直接得到正确的结果：如果程序是独立运行的，就返回一个本地执行环境；如果是创建了 jar 包，然后从命令行调用它并提交到集群执行，那么就返回集群的执行环境。也就是说，这个方法会根据当前运行的方式，自行决定该返回什么样的运行环境。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br></code></pre></td></tr></table></figure>

<p>这种方式，用起来简单高效，是最常用的一种创建执行环境的方式。</p>
</li>
<li><p><code>createLocalEnviroment</code>  </p>
<p>这个方法返回一个本地执行环境。可以在调用时传入一个参数，指定默认的并行度；如果不传入，则没人并行度就是本地的 CPU 核心数。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">StreamExecutionEnvironment localEnv = StreamExecutionEnvironment.createLocalEnvironment();<br></code></pre></td></tr></table></figure>
</li>
<li><p><code>createRemoteEnvironment</code>  </p>
<p>这个方法返回集群执行环境。需要在调用时指定 JobManager 的主机名和端口号，并指定要在集群中运行的Jar包。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java">StreamExecutionEnvironment remoteEnv = StreamExecutionEnvironment<br>        .createRemoteEnvironment(<br>            <span class="hljs-string">"host"</span>,                   <span class="hljs-comment">// JobManager主机名</span><br>            <span class="hljs-number">1234</span>,                     <span class="hljs-comment">// JobManager进程端口号</span><br>            <span class="hljs-string">"path/to/jarFile.jar"</span>  <span class="hljs-comment">// 提交给JobManager的JAR包</span><br>        );<br></code></pre></td></tr></table></figure>

<p>在获取到程序执行环境后，我们还可以对执行环境进行灵活的设置。比如可以全局设置程序的并行度、禁用算子链，还可以定义程序的时间语义、配置容错机制。</p>
</li>
</ol>
<h2 id="1-2、执行模式（Execution-Mode）"><a href="#1-2、执行模式（Execution-Mode）" class="headerlink" title="1.2、执行模式（Execution Mode）"></a>1.2、执行模式（Execution Mode）</h2><p>从 Flink1.12 开始，官方推荐的做法是直接使用 DataStream API，在提交任务时通过将执行模式设为 BATCH 来进行批处理。不建议使用 DataSet API。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 流处理环境</span><br>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br></code></pre></td></tr></table></figure>

<p>DataStream API 执行模式包括：流执行模式、批执行模式和自动模式</p>
<ul>
<li><p>流执行模式（Streaming）<br>这是 DataStream API 最经典的模式，一般用于需要持续实时处理的无界数据流。默认情况下，程序使用的就是 Streaming 执行模式。</p>
</li>
<li><p>批执行模式（Batch）<br>专门用于批处理的执行模式</p>
</li>
<li><p>自动模式（AutoMatic）<br>在这种模式下，将由程序根据输入数据源是否有界，来自动选择执行模式。<br>批执行模式的使用。主要有两种方式：  </p>
<ol>
<li><p>通过命令行配置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">bin/flink run -Dexecution.runtime-mode=BATCH ...<br></code></pre></td></tr></table></figure>
</li>
<li><p>通过代码配置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br>env.setRuntimeMode(RuntimeExecutionMode.BATCH);<br></code></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<h2 id="1-3、触发程序执行"><a href="#1-3、触发程序执行" class="headerlink" title="1.3、触发程序执行"></a>1.3、触发程序执行</h2><p>需要注意的是，写完输出（Sink）操作并不代表程序已经结束。因为当 <code>main()</code> 方法被调用时，其实只是定义了作业的每个执行操作如何添加到数据流图中；这时候并没有真正处理数据。因为数据可能还没有来。</p>
<p>Flink 是由事件驱动的，只有等到数据到来，才会触发真正的计算，这也被称为“延迟执行”或“懒执行”。所以我们需要显示地调用执行环境的 <code>execute()</code> 方法来触发程序的执行。<code>execute()</code> 方法讲一直等待作业完成，返回一个执行结果（JobExecutionResult）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">env.execute();<br></code></pre></td></tr></table></figure>


<h1 id="2、源算子（Source）"><a href="#2、源算子（Source）" class="headerlink" title="2、源算子（Source）"></a>2、源算子（Source）</h1><p>Fink 可以从各种来源获取数据，如何构建 DataStream 进行转换处理。一般将数据地输入来源称为数据源（data source），而读取数据的算子就是源算子。所以，source 就是我们整个处理程序的输入端。 </p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_10-14-38.png" srcset="/img/loading.gif" lazyload>  </p>
<ul>
<li><p>在 Flink1.12 以前，旧的添加 source 的方法是调用执行环境的 <code>addSource()</code> 方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">DataStream&lt;String&gt; stream = env.addSource(...);<br></code></pre></td></tr></table></figure>

<p>方法传入的参数是一个“源函数”（source function），需要实现 SourceFunction 接口。</p>
</li>
<li><p>从 Flink1.12 开始，主要使用流批一体的新 Source 架构：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">DataStreamSource&lt;String&gt; stream = env.fromSource(…)<br></code></pre></td></tr></table></figure></li>
</ul>
<p>Flink 直接提供了很多预实现的接口，此外还有很多外部连接工具也帮我们实现了对应的 Source，通常情况下足以应对我们的实际需求。</p>
<h2 id="2-1、准备工作"><a href="#2-1、准备工作" class="headerlink" title="2.1、准备工作"></a>2.1、准备工作</h2><p>为了方便练习，我们创建 WaterSensor 类作为数据模型。</p>
<table>
<thead>
<tr>
<th>字段名</th>
<th>数据类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>String</td>
<td>水位传感器类型</td>
</tr>
<tr>
<td>ts</td>
<td>Long</td>
<td>传感器记录时间戳</td>
</tr>
<tr>
<td>vc</td>
<td>Integer</td>
<td>水位记录</td>
</tr>
</tbody></table>
<p>具体代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Data</span><br><span class="hljs-meta">@NoArgsConstructor</span><br><span class="hljs-meta">@AllArgsConstructor</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">WaterSensor</span> </span>&#123;<br>    <span class="hljs-keyword">private</span> String id;<br>    <span class="hljs-keyword">private</span> Long ts;<br>    <span class="hljs-keyword">private</span> Integer vc;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>这里需要注意的点：</p>
<ul>
<li>类是公共的</li>
<li>所有属性都是公有的</li>
<li>所有属性的类型都是可以序列化的</li>
</ul>
<p>Flink 会把这样的类作为一种特殊的 POJO（Plain Ordinary Java Object 简单的 Java 对象，实际就是普通 JavaBeans）数据类型来对待，方便数据的解析和序列化。</p>
<p>我们这里自定义的 POJO 类会在后面的代码中频繁使用，所以在后面的代码中碰到，把这里的 POJO 类导入就好了。</p>
<h2 id="2-2、从集合中读取数据"><a href="#2-2、从集合中读取数据" class="headerlink" title="2.2、从集合中读取数据"></a>2.2、从集合中读取数据</h2><p>最简单的读取数据的方式，就是在代码中直接创建一个 Java 集合，然后调用执行环境的 fromCollection 方法进行读取。这相当于将数据临时存储到内存中，形成特殊的数据结构后，作为数据源使用，一般用于测试。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Demo01_CollectionSource</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        Configuration conf = <span class="hljs-keyword">new</span> Configuration();<br>        conf.setInteger(<span class="hljs-string">"rest.port"</span>, <span class="hljs-number">3333</span>);<br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(conf);<br><br>        <span class="hljs-comment">//从集合中获取数据，用于测试代码的逻辑是否有bug</span><br>        env.fromCollection(Arrays.asList(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>)).print();<br><br>        <span class="hljs-comment">//基于元素成绩</span><br>        env.fromElements(<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>,<span class="hljs-number">10</span>,<span class="hljs-number">11</span>,<span class="hljs-number">12</span>).printToErr();<br><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>


<h2 id="2-3、从文件中读取数据"><a href="#2-3、从文件中读取数据" class="headerlink" title="2.3、从文件中读取数据"></a>2.3、从文件中读取数据</h2><p>真正的实际应用中，自然不会直接将数据写在代码中。通常情况下，我们会从存储介质中获取数据，一个比较常见的方式就是读取日志文件。这也是批处理中最常见的读取方式。<br>读取文件，需要添加文件连接器依赖:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-connector-files<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure>

<p>代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Demo02_FileSource</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建Flink配置类（空参创建的话都是默认值）</span><br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//修改配置类中的WebUI端口号</span><br>        configuration.setInteger(<span class="hljs-string">"rest.port"</span>,<span class="hljs-number">3333</span>);<br>        <span class="hljs-comment">//创建Flink环境（并且传入配置对象）</span><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(configuration);<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * 引入file-connector</span><br><span class="hljs-comment">         *</span><br><span class="hljs-comment">         * forRecordStreamFormat(</span><br><span class="hljs-comment">         *      final StreamFormat&lt;T&gt; streamFormat, hadoop中的输入格式。代表输入的每一行数据的格式。</span><br><span class="hljs-comment">         *                                              压缩的文本，也能识别（部分）</span><br><span class="hljs-comment">         *      final Path...paths:读取的文件的路径，可以是单个文件，也可以是一个目录，可以是本地磁盘的目录，也可以是hdfs上的文件</span><br><span class="hljs-comment">         *          如果读取hdfs上的文件，需要引入hadoop-client的依赖</span><br><span class="hljs-comment">         *  )</span><br><span class="hljs-comment">         */</span><br><br>        <span class="hljs-comment">//获取数据源</span><br>        FileSource&lt;String&gt; source = FileSource.forRecordStreamFormat(<span class="hljs-keyword">new</span> TextLineInputFormat(), <span class="hljs-keyword">new</span> Path(<span class="hljs-string">"data/ws.json"</span>)).build();<br><br>        <span class="hljs-comment">//使用就算环境，调用source算子去读数据</span><br>        DataStreamSource&lt;String&gt; streamSource = env.fromSource(source, WatermarkStrategy.noWatermarks(), <span class="hljs-string">"myfile"</span>);<br><br>        <span class="hljs-comment">//简单打印</span><br>        streamSource.print();<br><br>        <span class="hljs-comment">//执行</span><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>说明：</p>
<ul>
<li>参数可以是目录，也可以是文件；还可以从 HDFS 目录下读取，使用路径 <code>hdfs://…</code></li>
<li>路径可以是相对路径，也可以是绝对路径</li>
<li>相对路径是从系统属性 <code>user.dir</code> 获取路径；idea 下是 project 的根目录，standalone 模式下是集群节点根目录。</li>
</ul>
<h2 id="2-4、从-Soceket-读取数据"><a href="#2-4、从-Soceket-读取数据" class="headerlink" title="2.4、从 Soceket 读取数据"></a>2.4、从 Soceket 读取数据</h2><p>不论从集合还是文件，我们读取的其实都是有界数据。在流处理的场景中，数据往往是无界的。  </p>
<p>我们之前用到的读取 socket 文本流，就是流处理场景。但是这种方式由于吞吐量小、稳定性较差，一般也是用于测试。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">DataStream&lt;String&gt; stream = env.socketTextStream(<span class="hljs-string">"hadoop102"</span>, <span class="hljs-number">9999</span>);<br></code></pre></td></tr></table></figure>


<h2 id="2-5、从-Kafka-读取数据"><a href="#2-5、从-Kafka-读取数据" class="headerlink" title="2.5、从 Kafka 读取数据"></a>2.5、从 Kafka 读取数据</h2><p>Flink 官方提供了连接工具 flink-connector-kafka，帮我们实现了一个消费者 FlinkKafkaConsumer，它就是用来读取 Kafka 数据的 SourceFunction。  </p>
<p>所以想要以 Kafka 作为数据源获取数据，我们只需要引入 Kafka 连接器的依赖。Flink 官方提供的是一个通用的 Kafka 连接器，它会自动跟踪最新版本的 Kafka 客户端。目前最新版本只支持 0.10.0 版本以上的 Kafka。这里我们需要导入的依赖如下。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-connector-kafka<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Demo03_KafkaSource</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建Flink配置类（空参创建的话都是默认值）</span><br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//修改配置类中的WebUI端口号</span><br>        configuration.setInteger(<span class="hljs-string">"rest.port"</span>,<span class="hljs-number">3333</span>);<br>        <span class="hljs-comment">//创建Flink环境（并且传入配置对象）</span><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(configuration);<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * 构造一个Source</span><br><span class="hljs-comment">         *      kafkaSource.&lt;OUT&gt;builder()</span><br><span class="hljs-comment">         *          OUT指kafka中读取的数据的value类型</span><br><span class="hljs-comment">         */</span><br>        KafkaSource&lt;String&gt; kafkaSource = KafkaSource.&lt;String&gt;builder()<br>                <span class="hljs-comment">//声明kafka集群地址</span><br>                .setBootstrapServers(<span class="hljs-string">"hadoop102:9092"</span>)<br>                <span class="hljs-comment">//声明读取的主题</span><br>                .setTopics(<span class="hljs-string">"FlinkTest"</span>)<br>                <span class="hljs-comment">/**设置消费者组 Source算子可以有多个并行度，每个并行度都会被创建为一个Task，每个Task都是一个消费者组，但是多个消费者组属于同一个组</span><br><span class="hljs-comment">                 * 一个Source的Task可以消费一个主题的N个分区</span><br><span class="hljs-comment">                */</span><br>                .setGroupId(<span class="hljs-string">"flink"</span>)<br>                <span class="hljs-comment">/**</span><br><span class="hljs-comment">                 * 设置消费者的消费策略</span><br><span class="hljs-comment">                 *  从头消费：earliest</span><br><span class="hljs-comment">                 *  从尾消费：latest</span><br><span class="hljs-comment">                 */</span><br>                <span class="hljs-comment">//没有设置策略的话是从头消费</span><br>                <span class="hljs-comment">//  flink 程序在启动的时候，从之前备份的状态中读取offsets，从offsets位置继续往后消费！</span><br>                <span class="hljs-comment">//如果没有备份，此时参考消费策略</span><br>                <span class="hljs-comment">//从头消费</span><br>                <span class="hljs-comment">//    .setStartingOffsets(OffsetsInitializer.earliest())</span><br>                <span class="hljs-comment">//从 kafka 读取当前组上次提交的 offset 位置，如果这个组没有提交过，再从头消费</span><br>                <span class="hljs-comment">//.setStartingOffsets(OffsetsInitializer.committedOffsets(OffsetResetStrategy.EARLIEST))</span><br><br><br>                <span class="hljs-comment">/**</span><br><span class="hljs-comment">                 * 如果你消费的数据，是没有 key 的，只需要设置 value 的反序列化器：setValueOnlyDeserializer</span><br><span class="hljs-comment">                 * 如果你消费的数据，有 key，需要设置 key-value 的反序列化器：setDeserializer</span><br><span class="hljs-comment">                 */</span><br>                .setValueOnlyDeserializer(<span class="hljs-keyword">new</span> SimpleStringSchema())<br>                <span class="hljs-comment">//设置是否自动提交消费的 offset</span><br>                .setProperty(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="hljs-string">"true"</span>)<br>                <span class="hljs-comment">//设置自动提交的时间间隔</span><br>                .setProperty(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="hljs-string">"1000"</span>)<br>                .build();<br><br>                env.fromSource(kafkaSource, WatermarkStrategy.noWatermarks(),<span class="hljs-string">"kafka"</span>).print();<br><br>                env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>


<h2 id="2-6、从数据生成器读取数据"><a href="#2-6、从数据生成器读取数据" class="headerlink" title="2.6、从数据生成器读取数据"></a>2.6、从数据生成器读取数据</h2><p>Flink 从 1.11 开始提供了一个内置的 DataGen 连接器，主要是用于生成一些随机数，用于在没有数据源的时候，进行流任务的测试以及性能测试等。1.17 提供了新的Source写法，需要导入依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-connector-datagen<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Demo04_DataGenSource</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建Flink配置类（空参创建的话都是默认值）</span><br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//修改配置类中的WebUI端口号</span><br>        configuration.setInteger(<span class="hljs-string">"rest.port"</span>,<span class="hljs-number">3333</span>);<br>        <span class="hljs-comment">//创建Flink环境（并且传入配置对象）</span><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(configuration);<br><br>        String[] ids=&#123;<span class="hljs-string">"s1"</span>,<span class="hljs-string">"s2"</span>,<span class="hljs-string">"s3"</span>&#125;;<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * 模拟源源不断的WaterSensor</span><br><span class="hljs-comment">         *</span><br><span class="hljs-comment">         * DataGeneratorSource(</span><br><span class="hljs-comment">         * GeneratorFunction&lt;Long,OUT&gt; generationFunction,函数帮你模拟想要的数据OUT，你要模拟的数据类型</span><br><span class="hljs-comment">         * Long count，一共要模拟多少条数据</span><br><span class="hljs-comment">         * RateLimiterStrategy rateLimiterStrategy,速率限制</span><br><span class="hljs-comment">         * TypeInformation&lt;OUT&gt; typeInfo 补充OUT的类型信息</span><br><span class="hljs-comment">         * )</span><br><span class="hljs-comment">         */</span><br><br>        <span class="hljs-comment">//模拟数据</span><br>        DataGeneratorSource&lt;WaterSensor&gt; source = <span class="hljs-keyword">new</span> DataGeneratorSource&lt;WaterSensor&gt;(<br>            <span class="hljs-keyword">new</span> GeneratorFunction&lt;Long,WaterSensor&gt;()<br>            &#123;<br>                <span class="hljs-meta">@Override</span><br>                <span class="hljs-function"><span class="hljs-keyword">public</span> WaterSensor <span class="hljs-title">map</span><span class="hljs-params">(Long aLong)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>                    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> WaterSensor(<br>                            ids[RandomUtils.nextInt(<span class="hljs-number">0</span>,ids.length)],<br>                            System.currentTimeMillis(),<br>                            RandomUtils.nextInt(<span class="hljs-number">100</span>,<span class="hljs-number">30000</span>)<br>                    );<br>                &#125;<br>            &#125;,<br>            Long.MAX_VALUE,<br>            RateLimiterStrategy.perSecond(<span class="hljs-number">5</span>d),<br>            TypeInformation.of(WaterSensor<span class="hljs-class">.<span class="hljs-keyword">class</span>)</span><br><span class="hljs-class"></span><br><span class="hljs-class">        )</span>;<br><br>        <span class="hljs-comment">//使用计算环境，调用fromSource算子去读数据</span><br>        DataStreamSource&lt;WaterSensor&gt; sensorDataStreamSource = env.fromSource(source, WatermarkStrategy.noWatermarks(), <span class="hljs-string">"dg"</span>);<br><br>        <span class="hljs-comment">//打印</span><br>        sensorDataStreamSource.print();<br><br>        <span class="hljs-comment">//执行</span><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>


<h2 id="2-7、Flink-支持的数据类型"><a href="#2-7、Flink-支持的数据类型" class="headerlink" title="2.7、Flink 支持的数据类型"></a>2.7、Flink 支持的数据类型</h2><p>1、Flink 的类型系统  </p>
<p>Flink 使用”类型信息“（TypeInformation）来统一表示数据类型。TypeInformation 类是 Flink 中所有类型描述符的基类。它涵盖了类型的一些基本属性，并为每个数据类型生成特定的序列化器、反序列化器和比较器。</p>
<p>2、Flink 支持的数据类型  </p>
<p>对于常见的 Java 和 Scala 数据类型，Flink 都是支持的。Flink 在内部，Flink 对支持不同的类型进行了划分，这些类型可以在Types工具类中找到：  </p>
<ol>
<li><p>基本类型。所有 Java 基本类型及其包装类，再加上 Void、String、Date、BigDecimal 和 BigInteger。  </p>
</li>
<li><p>数组类型。包括基本类型数组（Primitive_Array）和对象数组（Object_Array）。</p>
</li>
<li><p>复合数据类型。</p>
<ul>
<li>Java 元组类型（Tuple）：这是 Flink 内置的元组类型，是 Java API 的一部分。最多 25 个字段，也就是从Tuple0~Tuple25，不支持空字段。</li>
<li>Scala 样例类及 Scala 元组；不支持空字段。</li>
<li>行类型（ROW）：可以认为是具有任意个字段的元组，并支持空字段。</li>
<li>POJO：Flink 自定义的类似于 Java Bean 模式的类。</li>
</ul>
</li>
<li><p>辅助类型。Option、Either、List、Map 等</p>
</li>
<li><p>泛型类型（Generic）。Flink 支持所有的 Java 类和 Scala 类。不过如果没有按照上面 POJO 类型的要求来定义，就会被 Flink 当作泛型类来处理。Flink 会把泛型类型当作黑盒，无法获取它们内部的属性；它们也不是由 Flink 本身序列化的，而是由 Kryo 序列化的。  </p>
<p>在这些类型中，元组类型和 POJO 类型最为灵活，因为它们支持创建复杂类型。而相比之下，POJO 还支持在键（key）的定义中直接使用字段名，这会让我们的代码可读性大大增加。所以，在项目实践中，往往会将流处理程序中的元素类型定为 Flink 的 POJO 类型。  </p>
<p>Flink 对 POJO 类型的要求如下：</p>
<ul>
<li>类是公有（public）的</li>
<li>有一个无参的构造方法</li>
<li>所有属性都是公有（public）的</li>
<li>所有属性的类型都是可以序列化的</li>
</ul>
</li>
</ol>
<p>3、类型提示（Type Hints）  </p>
<p>Flink 还具有一个类型提取系统，可以分析函数的输入和返回类型，自动获取类型信息，从而获得对应的序列化器和反序列化器。但是，由于 Java 中泛型擦除的存在，在某些特殊情况下（比如 Lambda 表达式中），自动提前的信息是不够精细的，只告诉 Flink 当前的元素由“船头、船身、船尾”构成，根本无法重建出“大船”的模样；这时就需要显式地提供类型信息，才能使应用程序正常工作或提高其性能。</p>
<p>为了解决这类问题，Java API提供了专门的“类型同时”（type hints）  </p>
<p>回忆一下之前的 word count 流处理程序，我们在将 String 类型的每个词转换成（word，count）二元组后，就明确地用 returns 指定了返回的类型。因为对于 map 里传入了 Lambda 表达式，系统只能推断出返回的是Tuple2 类型，而无法得到 Tuple&lt;String,Long&gt;。只有显示地告诉系统当前的返回类型，才能正确地解析出完整数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">.map(word -&gt; Tuple2.of(word, <span class="hljs-number">1L</span>))<br>.returns(Types.TUPLE(Types.STRING, Types.LONG));<br></code></pre></td></tr></table></figure>

<p>Flink 还专门提供了 TypeHint 类，它可以捕获泛型的类型信息，并且一直记录下来，为运行时通过足够的信息。我们同样可以通过 returns() 方法，明确地指定转换之后的 DataStream 里元素的类型。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">returns(<span class="hljs-keyword">new</span> TypeHint&lt;Tuple2&lt;Integer, SomeType&gt;&gt;()&#123;&#125;)<br></code></pre></td></tr></table></figure>


<h1 id="3、转换算子（Transformation）"><a href="#3、转换算子（Transformation）" class="headerlink" title="3、转换算子（Transformation）"></a>3、转换算子（Transformation）</h1><p>数据源读入数据之后，我们就可以使用各种转换算子，将一个或多个 DataStream 转换为新的 DataStream。  </p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_10-14-39.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="3-1、基本转换算子（map-x2F-filter-x2F-flatMap）"><a href="#3-1、基本转换算子（map-x2F-filter-x2F-flatMap）" class="headerlink" title="3.1、基本转换算子（map&#x2F;filter&#x2F;flatMap）"></a>3.1、基本转换算子（map&#x2F;filter&#x2F;flatMap）</h2><h3 id="3-1-1、映射（map）"><a href="#3-1-1、映射（map）" class="headerlink" title="3.1.1、映射（map）"></a>3.1.1、映射（map）</h3><p>map 是大家非常熟悉的大数据操作算子，主要用于将数据流中的数据进行转换，形成新的数据流。简单来说，就是一个“一一映射”，消费一个元素就产出一个元素。  </p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_10-14-40.png" srcset="/img/loading.gif" lazyload>  </p>
<p>我们只需要基于 DataStream 调用 <code>map()</code> 方法就可以进行转换处理。方法需要传入的参数是接口 <code>MapFunction</code> 的实现；返回值类型还是 DataStream，不过泛型（流中的元素类型）可能改变。</p>
<p>下面是模拟读取数据库数据</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Demo01_Map</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建Flink配置类（空参创建的话都是默认值）</span><br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//修改配置类中的WebUI端口号</span><br>        configuration.setInteger(<span class="hljs-string">"rest.port"</span>,<span class="hljs-number">3333</span>);<br>        <span class="hljs-comment">//创建Flink环境（并且传入配置对象）</span><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(configuration);<br><br>        <span class="hljs-comment">//设置并行度是1</span><br>        env.setParallelism(<span class="hljs-number">1</span>);<br><br>        List&lt;Integer&gt; nums = Arrays.asList(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>);<br>        <br>        <span class="hljs-comment">// 方式一：传入匿名类，实现 MapFunction</span><br>        <span class="hljs-comment">//env.fromCollection(nums).map(new MapFunction&lt;WaterSensor, String&gt;() &#123;</span><br>        <span class="hljs-comment">//    @Override</span><br>        <span class="hljs-comment">//    public String map(WaterSensor e) throws Exception &#123;</span><br>        <span class="hljs-comment">//        return e.id;</span><br>        <span class="hljs-comment">//    &#125;</span><br>        <span class="hljs-comment">//&#125;).print();</span><br>        <br>        <span class="hljs-comment">// 方式二：传入 MapFunction 的实现类</span><br>        env.fromCollection(nums)<br>                .map(<span class="hljs-keyword">new</span> MyMapFunction())<br>                .print();<br>        env.execute();<br><br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyMapFunction</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">RichMapFunction</span>&lt;<span class="hljs-title">Integer</span>, <span class="hljs-title">String</span>&gt; </span>&#123;<br><br>        <span class="hljs-keyword">private</span> String conn;<br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">map</span><span class="hljs-params">(Integer integer)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br><br>            <span class="hljs-comment">//使用连接，读取数据库</span><br>            System.out.println(integer + <span class="hljs-string">"使用"</span> + conn);<br>            <span class="hljs-keyword">return</span> integer.toString();<br>        &#125;<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * RichFunction</span><br><span class="hljs-comment">         *          在Task被创建的时候，执行一次</span><br><span class="hljs-comment">         * <span class="hljs-doctag">@param</span> parameters</span><br><span class="hljs-comment">         * <span class="hljs-doctag">@throws</span> Exception</span><br><span class="hljs-comment">         */</span><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">open</span><span class="hljs-params">(Configuration parameters)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>            <span class="hljs-comment">//模拟创建连接</span><br>            conn=<span class="hljs-string">"连接"</span>;<br>            System.out.println(<span class="hljs-string">"创建好了连接.................."</span>);<br>        &#125;<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * RichFunction</span><br><span class="hljs-comment">         *          在Task关闭的时候，执行一次</span><br><span class="hljs-comment">         * <span class="hljs-doctag">@throws</span> Exception</span><br><span class="hljs-comment">         */</span><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">close</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>            <span class="hljs-comment">//关闭连接</span><br>            System.out.println(<span class="hljs-string">"关闭了连接..................."</span>);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>上面代码中，MapFuntion 实现类的泛型类型与输入数据类型和输出数据的类型有关。在实现 MapFunction 接口的时候，需要指定两个泛型，分别是输入事件和输出事件的类型，还需要重写一个 <code>map()</code> 方法，定义从一个输入事件转换为另一个输出事件的具体逻辑。</p>
<h3 id="3-1-2、过滤（filter）"><a href="#3-1-2、过滤（filter）" class="headerlink" title="3.1.2、过滤（filter）"></a>3.1.2、过滤（filter）</h3><p>filter 转换操作，顾名思义是对数据流执行一个过滤，通过一个布尔条件表达式设置过滤条件，对于每一个流内元素进行判断，若为 true 则元素正常输出，若为 false 则元素被过滤掉。  </p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_10-14-42.png" srcset="/img/loading.gif" lazyload>  </p>
<p>进行 filter 转换之后的新数据流的数据类型与原数据流是相同的。filter 转换需要传入的参数需要实现<code>FilterFunction</code> 接口，而 <code>FilterFunction</code> 内要实现 <code>filter()</code> 方法，就相当于一个返回布尔类型的条件表达式。</p>
<p>输出偶数：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Demo02_Filter</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建Flink配置类（空参创建的话都是默认值）</span><br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//修改配置类中的WebUI端口号</span><br>        configuration.setInteger(<span class="hljs-string">"rest.port"</span>,<span class="hljs-number">3333</span>);<br>        <span class="hljs-comment">//创建Flink环境（并且传入配置对象）</span><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(configuration);<br><br>        List&lt;Integer&gt; nums = Arrays.asList(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>);<br><br>        env.fromCollection(nums)<br>                .filter(integer -&gt; integer%<span class="hljs-number">2</span>==<span class="hljs-number">0</span>)<br>                .print();<br><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>


<h3 id="3-1-3、扁平映射（flatMap）"><a href="#3-1-3、扁平映射（flatMap）" class="headerlink" title="3.1.3、扁平映射（flatMap）"></a>3.1.3、扁平映射（flatMap）</h3><p>flatMap 操作又称为扁平映射，主要是将数据流中的整体（一般是集合类型）拆分成一个一个的个体使用。消费一个元素，可以产生 0 到多个元素。flatMap 可以认为是“扁平化”（flatten）和“映射”（map）两步操作的结合，也就是先按照某种规则对数据进行打散拆分，再对拆分后的元素做转换处理。 </p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_10-14-41.png" srcset="/img/loading.gif" lazyload>    </p>
<p>同 map 一样，flatMap 也可以使用 Lambda 表达式或者 <code>FlatMapFunction</code> 接口实现类的方式来进行传参，返回值类型取决于所传参数的具体逻辑，可以与原数据流相同，也可以不同。</p>
<p>输出偶数，并且输出多次</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Demo03_FlatMap</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建Flink配置类（空参创建的话都是默认值）</span><br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//修改配置类中的WebUI端口号</span><br>        configuration.setInteger(<span class="hljs-string">"rest.port"</span>,<span class="hljs-number">3333</span>);<br>        <span class="hljs-comment">//创建Flink环境（并且传入配置对象）</span><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(configuration);<br><br><br>        List&lt;Integer&gt; nums = Arrays.asList(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>);<br><br>        <span class="hljs-comment">//炸裂(留下偶数)</span><br>        env.fromCollection(nums)<br>                .flatMap(<span class="hljs-keyword">new</span> FlatMapFunction&lt;Integer, Integer&gt;() &#123;<br>                    <span class="hljs-meta">@Override</span><br>                    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">flatMap</span><span class="hljs-params">(Integer integer, Collector&lt;Integer&gt; collector)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>                        <span class="hljs-keyword">if</span> (integer%<span class="hljs-number">2</span>==<span class="hljs-number">0</span>)&#123;<br>                            collector.collect(integer);<br>                            collector.collect(integer);<br>                            collector.collect(integer);<br>                            collector.collect(integer);<br>                        &#125;<br>                    &#125;<br>                &#125;)<br>                .print();<br><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>


<h2 id="3-2、聚合算子"><a href="#3-2、聚合算子" class="headerlink" title="3.2、聚合算子"></a>3.2、聚合算子</h2><p>计算的结果不仅依赖当前数据，还跟之前的数据有关，相当于要把所有数据聚在一起进行汇总合并—这就是所谓的“聚合”（Aggregation），类似于 MapReduce 中的 Reduce 操作。</p>
<h3 id="3-2-1、按键分区（KeyBy），要做聚合，需要先进行分区"><a href="#3-2-1、按键分区（KeyBy），要做聚合，需要先进行分区" class="headerlink" title="3.2.1、按键分区（KeyBy），要做聚合，需要先进行分区"></a>3.2.1、按键分区（KeyBy），要做聚合，需要先进行分区</h3><p>对于 Flink 而言，DataStream 是没有直接进行聚合的 API 的。因为我们对海量数据做聚合肯定要进行分区并行处理，这样才能提高效率。所以在 Flink 中，要做聚合，需要先进行分区；这个操作就是通过 KeyBy 来完成的。</p>
<p>KeyBy 是聚合前必须用到的一个算子。KeyBy 通过指定键（key），可以将一条流从逻辑上划分为不同的分区（partitions）。这里所说的分区，其实就是并行处理的子任务。</p>
<p>基于不同的 key，流中的数据将被分配到不同的分区中；这样一来，所有具有相同的 key 的数据，都将被发往同一个分区。  </p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_10-14-43.png" srcset="/img/loading.gif" lazyload>  </p>
<p>在内部，是通过计算 key 的哈希值（hash code），对分区进行取模运算来实现的，所以这里 key 如果是 POJO 的话，必须重写 hashCode 方法。  </p>
<p><code>keyBy()</code> 方法需要传入一个参数，这个参数指定了一个或一组 key。有很多不同的方法来指定 key；<br>比如 Tuple 数据类型，可以指定字段的位置或多个位置的组合；<br>对于 POJO 类型，可以指定字段的名称（String）；<br>另外，还可以传入 Lambda 表达式或者实现一个键选择器（KeySelector），用于说明从数据中提取 key 的逻辑。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Demo01_CommonAgg</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//获取Flink环境</span><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br><br>        DataStreamSource&lt;WaterSensor&gt; stream = env.fromElements(<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_1"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_1"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>),<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_2"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>),<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_3"</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br>        );<br><br>        <span class="hljs-comment">// 方式一：使用Lambda表达式</span><br>        KeyedStream&lt;WaterSensor, String&gt; keyedStream = stream.keyBy(e -&gt; e.id);<br><br>        <span class="hljs-comment">// 方式二：使用匿名类实现KeySelector</span><br>        KeyedStream&lt;WaterSensor, String&gt; keyedStream1 = stream.keyBy(<span class="hljs-keyword">new</span> KeySelector&lt;WaterSensor, String&gt;() &#123;<br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">getKey</span><span class="hljs-params">(WaterSensor e)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>                <span class="hljs-keyword">return</span> e.id;<br>            &#125;<br>        &#125;);<br><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>运行截图：</p>
<p><img src="/img/flink/00/6865.jpg" srcset="/img/loading.gif" lazyload></p>
<p>需要注意的是，keyBy 得到的结果将不再是 DataStream，而是会将 DataStream 转换为 KeyedStream。KeyedStream 可以认为是“分区流”或者“键控流”，它是对 DataStream 按照 key 的一个逻辑分区，所以泛型有两个类型：除去当前流中的元素类型外，还需要指定 key 的类型。</p>
<p>KeyedStream 也继承自 DataStream，所以基于它的操作也都归属于 DataStream API。但它跟之前的转换操作得到的 SingleOutputStreamOperator 不同，只是一个流的分区操作，并不是一个转换算子。KeyedStream 是一个非常重要的数据结构，只有基于它才可以做后续的聚合操作（比如 sum，reduce）。</p>
<h3 id="3-2-2、简单聚合（Sum-x2F-Min-x2F-MinBy-x2F-MaxBy）"><a href="#3-2-2、简单聚合（Sum-x2F-Min-x2F-MinBy-x2F-MaxBy）" class="headerlink" title="3.2.2、简单聚合（Sum&#x2F;Min&#x2F;MinBy&#x2F;MaxBy）"></a>3.2.2、简单聚合（Sum&#x2F;Min&#x2F;MinBy&#x2F;MaxBy）</h3><p>有了按键分区的数据流 KeyedStream，我们可以就可以给予它进行聚合操作了。Flink 为我们内置实现了一些最基本、最简单的聚合 API，主要有以下几种：</p>
<ul>
<li><code>sum()</code>:在输入流上，对指定的字段做叠加求和的操作。</li>
<li><code>min()</code>:在输入流上，对指定的字段求最小值</li>
<li><code>max()</code>:在输入流上，对指定的字段求最大值</li>
<li><code>minBy()</code>:与 <code>min()</code> 类似，在输入流上针对指定字段求最小值。不同的是，<code>min()</code> 只计算指定字段的最小值，其他字段会保留最初第一个数据的值；而 <code>minBy()</code> 则会返回包含字段最小值的整条数据</li>
<li><code>maxBy()</code>:与 <code>max()</code> 类似，在输入流上针对指定字段求最大值。两者区别与 <code>min()</code> 和 <code>MinBy()</code> 的区别一样。</li>
</ul>
<p>简单聚合算子使用很方便，语义也非常明确。这些聚合方法调用时，也需要传入参数；但并不像基本转换算子那样需要实现自定义函数，只要说明聚合指定字段就可以了。指定字段的方式有两种：<strong>指定位置和指定名称</strong></p>
<p>对于元组类型的数据，可以使用这两种方式来指定字段。需要注意的是，元组中字段的名称是以 f0、f1、f2、… 来命名的。</p>
<p>如果数据流的类型是 POJO 类，那么就只能通过指定字段名称来指定，不能通过位置来指定了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TransAggregation</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br>        DataStreamSource&lt;WaterSensor&gt; stream = env.fromElements(<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_1"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_1"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>),<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_2"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>),<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_3"</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br>        );<br>        stream.keyBy(e -&gt; e.id).max(<span class="hljs-string">"vc"</span>);    <span class="hljs-comment">// 指定字段名称</span><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>简单聚合算子返回的同样是一个 SingleOutputStreamOperator，也就是从 KeyedStream 又转换成了常规的 DataStream。所以可以这样理解：keyBy 和聚合是成对出现的，先分区、后聚合，得到的依然是一个 DataStream。而且经过简单聚合之后的数据流，元素的数据类型保持不变。</p>
<p>一个聚合算子，会为每一个 key 保存一个聚合的值，在 Flink 中我们把它叫作“状态”（state）。所以每当有一个新的数据输入，算子就会更新保存的聚合结果，并发送一个带有更新聚合值的事件到下游算子。对于无界流来说，这些状态是永远不会被清除的，所以我们使用聚合算子，一个只用在含有有限个 key 的数据流上。</p>
<h3 id="3-2-3、归约聚合（Reduce）"><a href="#3-2-3、归约聚合（Reduce）" class="headerlink" title="3.2.3、归约聚合（Reduce）"></a>3.2.3、归约聚合（Reduce）</h3><p>Reduce 可以对已有的数据进行归约处理，把每一个新输入的数据和当前已经归约出来的值再做一个聚合计算。  </p>
<p>Reduce 操作也会将 KeyedStream 转换为 DataStream。它不会改变流的元素数据类型，所以输出类型和输入类型是一样的。  </p>
<p>调用 KeyedStream 的 Reduce 方法时，需要传入一个参数，实现 ReduceFunction 接口。接口在源码中的定义如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">ReduceFunction</span>&lt;<span class="hljs-title">T</span>&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title">Function</span>, <span class="hljs-title">Serializable</span> </span>&#123;<br>    <span class="hljs-function">T <span class="hljs-title">reduce</span><span class="hljs-params">(T value1, T value2)</span> <span class="hljs-keyword">throws</span> Exception</span>;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>ReduceFunction 接口里需要实现 <code>Reduce()</code> 方法，这个方法接受两个输入事件，经过转换处理之后输出一个相同类型的事件。在流处理的底层实现过程中，实际上是将中间“合并的结果”作为任务的一个状态保存起来；之后每来一个新的数据，就和之前的聚合状态进一步做归约。  </p>
<p>我们可以单独定义一个函数类实现 ReduceFunction 接口，也可以直接传入一个匿名类。当然，同样也可以通过传入 Lambda 表达式实现类似的功能。</p>
<p>定义一个 WaterSensorMapFunction：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">WaterSensorMapFunction</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">MapFunction</span>&lt;<span class="hljs-title">String</span>, <span class="hljs-title">WaterSensor</span>&gt; </span>&#123;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> WaterSensor <span class="hljs-title">map</span><span class="hljs-params">(String s)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        String[] fileds = s.split(<span class="hljs-string">","</span>);<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> WaterSensor(fileds[<span class="hljs-number">0</span>],Long.valueOf(fileds[<span class="hljs-number">1</span>]),Integer.valueOf(fileds[<span class="hljs-number">2</span>]));<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>案例：使用 Reduce 实现取最小值功能：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 规律：无KeyBy(分组)，无聚合</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * reduce(ReduceFunction x)：</span><br><span class="hljs-comment"> *          ReduceFunction的逻辑由用户自己编写，灵活点</span><br><span class="hljs-comment"> *              特点：</span><br><span class="hljs-comment"> *                  输入的类型和输出的类型必须是一致的</span><br><span class="hljs-comment"> *                  两两聚合。每两条数据，执行一次聚合</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Demo02_Reduce</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//获取Flink环境</span><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br><br>        <span class="hljs-comment">//获取数据源</span><br>        DataStreamSource&lt;String&gt; ds = env.socketTextStream(<span class="hljs-string">"hadoop102"</span>, <span class="hljs-number">9999</span>);<br>        <span class="hljs-comment">//设置并行度是1</span><br>        env.setParallelism(<span class="hljs-number">1</span>);<br>        <br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * SingleOutputStreamOperator:这个算子是不具有聚合功能的</span><br><span class="hljs-comment">         */</span><br>        <span class="hljs-comment">//一对一映射为WaterSensor对象</span><br>        SingleOutputStreamOperator&lt;WaterSensor&gt; map = ds.map(<span class="hljs-keyword">new</span> WaterSensorMapFunction());<br><br>        <span class="hljs-comment">//KeyedStream：有聚合功能</span><br>        KeyedStream&lt;WaterSensor, String&gt; keyBy = map.keyBy(WaterSensor::getId);<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * 如果是第一条数据的话是不走方法的，而是直接将数据储存在value1中</span><br><span class="hljs-comment">         * 后面的每个数据都会走这个方法，然后返回值会重新写入到value1中</span><br><span class="hljs-comment">         */</span><br>        keyBy.reduce(<span class="hljs-keyword">new</span> ReduceFunction&lt;WaterSensor&gt;() &#123;<br>            <span class="hljs-comment">/**</span><br><span class="hljs-comment">             * value1:上一次计算的结果</span><br><span class="hljs-comment">             * value2:当前最新到达的数据</span><br><span class="hljs-comment">             */</span><br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-function"><span class="hljs-keyword">public</span> WaterSensor <span class="hljs-title">reduce</span><span class="hljs-params">(WaterSensor value1, WaterSensor value2)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>                <span class="hljs-comment">//实现minBy(vc)的效果</span><br>                <span class="hljs-comment">// if (value1.getVc() &lt;= value2.getVc())&#123;</span><br>                <span class="hljs-comment">//实现minBy(vc,false)的效果</span><br>                <span class="hljs-keyword">if</span> (value1.getVc()&lt;value2.getVc())&#123;<br>                    <span class="hljs-keyword">return</span> value1;<br>                &#125;<span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-keyword">return</span> value2;<br>                &#125;<br>            &#125;<br>        &#125;)<br>                .print();<br><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>


<p><img src="/img/flink/00/20230608125535.png" srcset="/img/loading.gif" lazyload></p>
<p>Reduce 和简单聚合算子一样，也要针对每一个 key 保存状态。因为状态不会清空，所以我们需要将 Reduce 算子作用在一个有限 key 的流上。</p>
<h2 id="3-3、用户自定义函数（user-defined-function，UDF）"><a href="#3-3、用户自定义函数（user-defined-function，UDF）" class="headerlink" title="3.3、用户自定义函数（user-defined function，UDF）"></a>3.3、用户自定义函数（user-defined function，UDF）</h2><p>用户自定义函数（user-defined function，UDF），即用户可以根据自身需求，重新实现算子的逻辑。</p>
<p>用户自定义函数分为：函数类、匿名函数、富函数类。</p>
<h3 id="3-3-1-函数类（Function-Classes）"><a href="#3-3-1-函数类（Function-Classes）" class="headerlink" title="3.3.1 函数类（Function Classes）"></a>3.3.1 函数类（Function Classes）</h3><p>Flink 暴露了所有 UDF 函数的接口，具体实现方式为接口或者抽象类，例如 MapFunction、FilterFunction、ReduceFunction 等。所以用户可以自定义一个函数类，实现对应的接口。</p>
<p>需求：用来从用户的点击数据中筛选包含“sensor_1”的内容：</p>
<p>方式一：实现 FilterFunction 接口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TransFunctionUDF</span> </span>&#123;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br><br>        DataStreamSource&lt;WaterSensor&gt; stream = env.fromElements(<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_1"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_1"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>),<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_2"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>),<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_3"</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br>        );<br>       <br>        DataStream&lt;String&gt; filter = stream.filter(<span class="hljs-keyword">new</span> UserFilter());<br>      <br>        filter.print();<br>        env.execute();<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">UserFilter</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">FilterFunction</span>&lt;<span class="hljs-title">WaterSensor</span>&gt; </span>&#123;<br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">filter</span><span class="hljs-params">(WaterSensor e)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>            <span class="hljs-keyword">return</span> e.id.equals(<span class="hljs-string">"sensor_1"</span>);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>方式二：通过匿名类来实现 FilterFunction 接口：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java">DataStream&lt;String&gt; stream = stream.filter(<span class="hljs-keyword">new</span> FilterFunction&lt; WaterSensor&gt;() &#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">filter</span><span class="hljs-params">(WaterSensor e)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-keyword">return</span> e.id.equals(<span class="hljs-string">"sensor_1"</span>);<br>    &#125;<br>&#125;);<br></code></pre></td></tr></table></figure>

<p>方法二的优化：为了类可以更加通用，我们还可以将用于过滤的关键字 “sensor_1” 抽象出来作为类的属性，调用构造方法时传进去。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java">DataStreamSource&lt;WaterSensor&gt; stream = env.fromElements(        <br>    <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_1"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),<br>    <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_1"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>),<br>    <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_2"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>),<br>    <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_3"</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br>);<br><br>DataStream&lt;String&gt; stream = stream.filter(<span class="hljs-keyword">new</span> FilterFunctionImpl(<span class="hljs-string">"sensor_1"</span>));<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FilterFunctionImpl</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">FilterFunction</span>&lt;<span class="hljs-title">WaterSensor</span>&gt; </span>&#123;<br>    <span class="hljs-keyword">private</span> String id;<br><br>    FilterFunctionImpl(String id) &#123; <span class="hljs-keyword">this</span>.id=id; &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">filter</span><span class="hljs-params">(WaterSensor value)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-keyword">return</span> thid.id.equals(value.id);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>方式三：采用匿名函数（Lambda）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TransFunctionUDF</span> </span>&#123;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br><br>        DataStreamSource&lt;WaterSensor&gt; stream = env.fromElements(<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_1"</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_1"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>),<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_2"</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>),<br>            <span class="hljs-keyword">new</span> WaterSensor(<span class="hljs-string">"sensor_3"</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br>        );    <br><br>        <span class="hljs-comment">// map 函数使用 Lambda 表达式，不需要进行类型声明</span><br>        SingleOutputStreamOperator&lt;String&gt; filter = stream.filter(sensor -&gt; <span class="hljs-string">"sensor_1"</span>.equals(sensor.id));<br><br>        filter.print();<br><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>


<h3 id="3-3-2-富函数类（Rich-Function-Classes）"><a href="#3-3-2-富函数类（Rich-Function-Classes）" class="headerlink" title="3.3.2 富函数类（Rich Function Classes）"></a>3.3.2 富函数类（Rich Function Classes）</h3><p>“富函数类”也是 DataStream API 提供的一个函数类的接口，所有的 Flink 函数类都有其 Rich 版本。富函数类一般是以抽象类的形式出现的。例如：RichMapFunction、RichFilterFunction、RichReduceFunction 等。</p>
<p>与常规函数类的不同主要在于，富函数类可以获取运行环境的上下文，并拥有一些生命周期方法，所以可以实现更复杂的功能。</p>
<p>Rich Function 有生命周期的概念。典型的生命周期方法有：</p>
<ul>
<li><code>open()</code> 方法：Rich Function 的初始化方法，也就是会开启一个算子的生命周期。当一个算子的实际工作方法例如 <code>map()</code> 或者 <code>filter()</code> 方法被调用之前，<code>open()</code> 会首先被调用。</li>
<li><code>close()</code> 方法：生命周期中的最后一个调用的方法，类似于结束方法。一般用来做一些清理工作。</li>
</ul>
<p>需要注意的是，这里的生命周期方法，对于一个并行子任务来说只会调用一次；而对应的，实际工作方法，例如RichMapFunction 中的 map，在每条数据来到后都会触发一次调用。</p>
<p>来看一个例子说明：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RichFunctionExample</span> </span>&#123;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br>        env.setParallelism(<span class="hljs-number">2</span>);<br><br>        env<br>                .fromElements(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)<br>                .map(<span class="hljs-keyword">new</span> RichMapFunction&lt;Integer, Integer&gt;() &#123;<br>                    <span class="hljs-meta">@Override</span><br>                    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">open</span><span class="hljs-params">(Configuration parameters)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>                        <span class="hljs-keyword">super</span>.open(parameters);<br>                        System.out.println(<span class="hljs-string">"索引是："</span> + getRuntimeContext().getIndexOfThisSubtask() + <span class="hljs-string">" 的任务的生命周期开始"</span>);<br>                    &#125;<br><br>                    <span class="hljs-meta">@Override</span><br>                    <span class="hljs-function"><span class="hljs-keyword">public</span> Integer <span class="hljs-title">map</span><span class="hljs-params">(Integer integer)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>                        <span class="hljs-keyword">return</span> integer + <span class="hljs-number">1</span>;<br>                    &#125;<br><br>                    <span class="hljs-meta">@Override</span><br>                    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">close</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>                        <span class="hljs-keyword">super</span>.close();<br>                        System.out.println(<span class="hljs-string">"索引是："</span> + getRuntimeContext().getIndexOfThisSubtask() + <span class="hljs-string">" 的任务的生命周期结束"</span>);<br>                    &#125;<br>                &#125;)<br>                .print();<br><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>运行截图：</p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_16-47-17.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="3-4、物理分区算子（Physical-Partitioning）"><a href="#3-4、物理分区算子（Physical-Partitioning）" class="headerlink" title="3.4、物理分区算子（Physical Partitioning）"></a>3.4、物理分区算子（Physical Partitioning）</h2><p>常见的物理分区策略有：随机分配（Random）、轮询分配（Round-Robin）、重缩放（Rescale）和广播（Broadcast）</p>
<h3 id="3-4-1、随机分区（Shuffle）"><a href="#3-4-1、随机分区（Shuffle）" class="headerlink" title="3.4.1、随机分区（Shuffle）"></a>3.4.1、随机分区（Shuffle）</h3><p>最简单的重分区方式就是直接“洗牌”。通过调用 DataStream 的 <code>.shuffle()</code> 方法，将数据随机地分配到下游算子的并行任务中去。</p>
<p>随机分区服从均匀分布（uniform distribution），所以可以把流中的数据随机打乱，均匀地传递到下游任务分区。因为是完全随机的，所以对于同样的输入数据, 每次执行得到的结果也不会相同。</p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_16-47-18.png" srcset="/img/loading.gif" lazyload>  </p>
<p>经过随机分区之后，得到的依然是一个 DataStream。  </p>
<p>我们可以做个简单测试：将数据读入之后直接打印到控制台，将输出的并行度设置为 2，中间经历一次 shuffle。执行多次，观察结果是否相同。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ShuffleExample</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br><br>        env.setParallelism(<span class="hljs-number">2</span>);<br><br>        DataStreamSource&lt;String&gt; stream = env.socketTextStream(<span class="hljs-string">"hadoop102"</span>, <span class="hljs-number">9999</span>);<br><br>        stream.shuffle().print();<br><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>第一次运行截图：<br><img src="/img/flink/00/Snipaste_2023-06-07_16-59-13.png" srcset="/img/loading.gif" lazyload><br>第二次运行截图：<br><img src="/img/flink/00/Snipaste_2023-06-07_16-59-31.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="3-4-2、轮询分区（Round-Robin）"><a href="#3-4-2、轮询分区（Round-Robin）" class="headerlink" title="3.4.2、轮询分区（Round-Robin）"></a>3.4.2、轮询分区（Round-Robin）</h3><p>轮询，简单来说就是“发牌”，按照先后顺序将数据做依次分发。通过调用 DataStream 的 <code>.rebalance()</code> 方法，就可以实现轮询重分区。rebalance 使用的是 Round-Robin 负载均衡算法，可以将输入流数据平均分配到下游的并行任务中去。</p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_16-59-32.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="3-4-3、重缩放分区（rescale）"><a href="#3-4-3、重缩放分区（rescale）" class="headerlink" title="3.4.3、重缩放分区（rescale）"></a>3.4.3、重缩放分区（rescale）</h3><p>重缩放分区和轮询分区非常相似。当调用 <code>rescale()</code> 方法时，其实底层也是使用 Round-Robin 算法进行轮询，但是只会将数据轮询发送到下游并行任务的一部分中。rescale 的做法是分成小团体，发牌人只给自己团体内的所有人轮流发牌。<br><img src="/img/flink/00/Snipaste_2023-06-07_16-59-33.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="3-4-4、广播（BroadCast）"><a href="#3-4-4、广播（BroadCast）" class="headerlink" title="3.4.4、广播（BroadCast）"></a>3.4.4、广播（BroadCast）</h3><p>这种方式其实不应该叫做“重分区”，因为经过广播之后，数据会在不同的分区都保留一份，可能进行重复处理。可以通过调用 <code>DataStream的broadcast()</code> 方法，将输入数据复制并发送到下游算子的所有并行任务中去。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">stream.broadcast()<br></code></pre></td></tr></table></figure>


<h3 id="3-4-5、全局分区（Global）"><a href="#3-4-5、全局分区（Global）" class="headerlink" title="3.4.5、全局分区（Global）"></a>3.4.5、全局分区（Global）</h3><p>全局分区也是一种特殊的分区方式。这种做法非常极端，通过调用 <code>.global()</code> 方法，会将所有的输入流数据都发送到下游算子的第一个并行子任务中去（0号）。这就相当于强行让下游任务并行度变成了 1，所以使用这个操作需要非常谨慎，可能对程序造成很大的压力。</p>
<h3 id="3-4-6、自定义分区（Custom）"><a href="#3-4-6、自定义分区（Custom）" class="headerlink" title="3.4.6、自定义分区（Custom）"></a>3.4.6、自定义分区（Custom）</h3><p>当 Flink 提供的所有分区策略都不能满足用户的需求时，我们可以通过使用 <code>partitionCustom()</code> 方法来自定义分区策略。</p>
<p>1、自定义分区器</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyPartitioner</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Partitioner</span>&lt;<span class="hljs-title">String</span>&gt; </span>&#123;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">partition</span><span class="hljs-params">(String key, <span class="hljs-keyword">int</span> numPartitions)</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> Integer.parseInt(key) % numPartitions;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>2、使用自定义分区</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PartitionCustomDemo</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br><span class="hljs-comment">//        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(<span class="hljs-keyword">new</span> Configuration());<br><br>        env.setParallelism(<span class="hljs-number">2</span>);<br><br>        DataStreamSource&lt;String&gt; socketDS = env.socketTextStream(<span class="hljs-string">"hadoop102"</span>, <span class="hljs-number">7777</span>);<br><br>        DataStream&lt;String&gt; myDS = socketDS<br>                .partitionCustom(<br>                        <span class="hljs-keyword">new</span> MyPartitioner(),<br>                        value -&gt; value);<br><br>        myDS.print();<br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>


<h2 id="3-5、分流"><a href="#3-5、分流" class="headerlink" title="3.5、分流"></a>3.5、分流</h2><p>所谓“分流”，就是将一条数据流拆分成完全独立的两条、甚至多条流。也就是基于一个 DataStream，定义一些筛选条件，将符合条件的数据拣选出来放到对应的流里。</p>
<p><img src="/img/flink/00/Snipaste_2024-06-06_22-54-26.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="3-5-1、简单实现（filter"><a href="#3-5-1、简单实现（filter" class="headerlink" title="3.5.1、简单实现（filter)"></a>3.5.1、简单实现（filter)</h3><p>其实根据条件筛选数据的需求，本身非常容易实现：只要针对同一条流多次独立调用 <code>.filter()</code> 方法进行筛选，就可以得到拆分之后的流了。</p>
<p>案例需求：读取一个整数数字流，将数据流划分为奇数流和偶数流。</p>
<p>代码实现:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Demo01_FilterDivide</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建Flink配置对象</span><br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//修改Flink的webUI端口配置</span><br>        configuration.setInteger(<span class="hljs-string">"rest.port"</span>,<span class="hljs-number">8888</span>);<br>        <span class="hljs-comment">//创建Flink环境</span><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(configuration);<br><br>        <span class="hljs-comment">//设置并行度是2</span><br>        env.setParallelism(<span class="hljs-number">2</span>);<br>        <span class="hljs-comment">//不能进行算子链的合并</span><br>        env.disableOperatorChaining();<br><br>        <span class="hljs-comment">//获取网络传输数据源，并且映射为数字</span><br>        SingleOutputStreamOperator&lt;Integer&gt; map = env.socketTextStream(<span class="hljs-string">"hadoop102"</span>, <span class="hljs-number">9999</span>)<br>                .name(<span class="hljs-string">"s"</span>)<br>                .map(Integer::valueOf);<br><br>        <span class="hljs-comment">//奇数一个流</span><br>        map.filter(s -&gt; s % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>).print(<span class="hljs-string">"奇数"</span>);<br>        <span class="hljs-comment">//偶数一个流</span><br>        map.filter(s -&gt; s % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>).print(<span class="hljs-string">"偶数"</span>);<br><br>        <span class="hljs-comment">//执行</span><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>这种实现非常简单，但代码显得有些冗余——我们的处理逻辑对拆分出的三条流其实是一样的，却重复写了三次。而且这段代码背后的含义，是将原始数据流 stream 复制三份，然后对每一份分别做筛选；这明显是不够高效的。我们自然想到，能不能不用复制流，直接用一个算子就把它们都拆分开呢？<br><img src="/img/flink/00/Snipaste_2023-06-07_20-57-21.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="3-5-2、使用测输出流"><a href="#3-5-2、使用测输出流" class="headerlink" title="3.5.2、使用测输出流"></a>3.5.2、使用测输出流</h3><p>简单来说，只需要调用上下文 ctx 的 <code>.output()</code> 方法，就可以输出任意类型的数据了。而侧输出流的标记和提取，都离不开一个“输出标签”（OutputTag），指定了侧输出流的id和类型。</p>
<p>代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SplitStreamByOutputTag</span> </span>&#123;    <br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br><br>        SingleOutputStreamOperator&lt;WaterSensor&gt; ds = env.socketTextStream(<span class="hljs-string">"hadoop102"</span>, <span class="hljs-number">7777</span>)<br>              .map(<span class="hljs-keyword">new</span> WaterSensorMapFunction());<br><br><br>        OutputTag&lt;WaterSensor&gt; s1 = <span class="hljs-keyword">new</span> OutputTag&lt;&gt;(<span class="hljs-string">"s1"</span>, Types.POJO(WaterSensor<span class="hljs-class">.<span class="hljs-keyword">class</span>))</span>&#123;&#125;;<br>        OutputTag&lt;WaterSensor&gt; s2 = <span class="hljs-keyword">new</span> OutputTag&lt;&gt;(<span class="hljs-string">"s2"</span>, Types.POJO(WaterSensor<span class="hljs-class">.<span class="hljs-keyword">class</span>))</span>&#123;&#125;;<br>       <span class="hljs-comment">//返回的都是主流</span><br>        SingleOutputStreamOperator&lt;WaterSensor&gt; ds1 = ds.process(<span class="hljs-keyword">new</span> ProcessFunction&lt;WaterSensor, WaterSensor&gt;()<br>        &#123;<br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">processElement</span><span class="hljs-params">(WaterSensor value, Context ctx, Collector&lt;WaterSensor&gt; out)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br><br>                <span class="hljs-keyword">if</span> (<span class="hljs-string">"s1"</span>.equals(value.getId())) &#123;<br>                    ctx.output(s1, value);<br>                &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (<span class="hljs-string">"s2"</span>.equals(value.getId())) &#123;<br>                    ctx.output(s2, value);<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-comment">//主流</span><br>                    out.collect(value);<br>                &#125;<br>            &#125;<br>        &#125;);<br><br>        ds1.print(<span class="hljs-string">"主流，非s1,s2的传感器"</span>);<br>        SideOutputDataStream&lt;WaterSensor&gt; s1DS = ds1.getSideOutput(s1);<br>        SideOutputDataStream&lt;WaterSensor&gt; s2DS = ds1.getSideOutput(s2);<br><br>        s1DS.printToErr(<span class="hljs-string">"s1"</span>);<br>        s2DS.printToErr(<span class="hljs-string">"s2"</span>);<br>        <br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>


<h2 id="3-6、基本合流操作"><a href="#3-6、基本合流操作" class="headerlink" title="3.6、基本合流操作"></a>3.6、基本合流操作</h2><p>在实际应用中，我们经常会遇到来源不同的多条流，需要将它们的数据进行联合处理。所以 Flink 中合流的操作会更加普遍，对应的 API 也更加丰富。</p>
<h3 id="3-6-1、联合（union）"><a href="#3-6-1、联合（union）" class="headerlink" title="3.6.1、联合（union）"></a>3.6.1、联合（union）</h3><p>最简单的合流操作，就是直接将多条流合在一起，叫作流的“联合”（union）。联合操作要求必须流中的数据类型必须相同，合并之后的新流会包括所有流中的元素，数据类型不变。  </p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_20-57-22.png" srcset="/img/loading.gif" lazyload>  </p>
<p>在代码中，我们只要基于 DataStream 直接调用 <code>.union()</code> 方法，传入其他 DataStream 作为参数，就可以实现流的联合了；得到的依然是一个 DataStream：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">stream1.union(stream2, stream3, ...)<br></code></pre></td></tr></table></figure>

<p>注意：<code>union()</code> 的参数可以是多个 DataStream，所以联合操作可以实现多条流的合并。</p>
<p>代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Demo01_Union</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建Flink配置对象</span><br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//修改Flink的webUI端口配置</span><br>        configuration.setInteger(<span class="hljs-string">"rest.port"</span>,<span class="hljs-number">8888</span>);<br>        <span class="hljs-comment">//创建Flink环境</span><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(configuration);<br><br>        env.setParallelism(<span class="hljs-number">1</span>);<br>        <span class="hljs-comment">//创建四个流(前三个流的元素是一致类型)</span><br>        DataStreamSource&lt;Integer&gt; ds = env.fromElements(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>);<br>        DataStreamSource&lt;Integer&gt; ds1 = env.fromElements(<span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>);<br>        DataStreamSource&lt;Integer&gt; ds2 = env.fromElements(<span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>, <span class="hljs-number">24</span>, <span class="hljs-number">25</span>);<br>        DataStreamSource&lt;String&gt; ds3 = env.fromElements(<span class="hljs-string">"1"</span>,<span class="hljs-string">"2"</span>,<span class="hljs-string">"3"</span>);<br><br>        <span class="hljs-comment">//合并为一个流 使用union算子的前提是流中的元素类型是一致的，要不然会报错导致用不了</span><br>        DataStream&lt;Integer&gt; unionDS = ds.union(ds1, ds2);<br>        unionDS.print();<br><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>运行截图：  </p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_21-01-40.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="3-6-2、连接（Connect）"><a href="#3-6-2、连接（Connect）" class="headerlink" title="3.6.2、连接（Connect）"></a>3.6.2、连接（Connect）</h3><p>流的联合虽然简单，不过受限于数据类型不能改变，灵活性大打折扣，所以实际应用较少出现。除了联合（union），Flink 还提供了另外一种方便的合流操作——连接（connect）。</p>
<p>1、连接流（Connect）  </p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_21-02-50.png" srcset="/img/loading.gif" lazyload></p>
<p>代码实现：需要分为两步：首先基于一条 DataStream 调用 <code>.connect()</code> 方法，传入另外一条DataStream 作为参数，将两条流连接起来，得到一个 ConnectedStreams；然后再调用同处理方法得到 DataStream。这里可以的调用的同处理方法有 <code>.map()/.flatMap()</code>，以及 <code>.process()</code> 方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ConnectDemo</span> </span>&#123;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br><br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br>        env.setParallelism(<span class="hljs-number">1</span>);<br><br><span class="hljs-comment">//        DataStreamSource&lt;Integer&gt; source1 = env.fromElements(1, 2, 3);</span><br><span class="hljs-comment">//        DataStreamSource&lt;String&gt; source2 = env.fromElements("a", "b", "c");</span><br><br>        SingleOutputStreamOperator&lt;Integer&gt; source1 = env<br>                .socketTextStream(<span class="hljs-string">"hadoop102"</span>, <span class="hljs-number">9999</span>)<br>                .map(i -&gt; Integer.parseInt(i));<br><br>        DataStreamSource&lt;String&gt; source2 = env.socketTextStream(<span class="hljs-string">"hadoop102"</span>, <span class="hljs-number">9998</span>);<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * TODO 使用 connect 合流</span><br><span class="hljs-comment">         * 1、一次只能连接 2条流</span><br><span class="hljs-comment">         * 2、流的数据类型可以不一样</span><br><span class="hljs-comment">         * 3、连接后可以调用 map、flatmap、process来处理，但是各处理各的</span><br><span class="hljs-comment">         */</span><br>        ConnectedStreams&lt;Integer, String&gt; connect = source1.connect(source2);<br><br>        SingleOutputStreamOperator&lt;String&gt; result = connect.map(<span class="hljs-keyword">new</span> CoMapFunction&lt;Integer, String, String&gt;() &#123;<br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">map1</span><span class="hljs-params">(Integer value)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-string">"来源于数字流:"</span> + value.toString();<br>            &#125;<br><br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">map2</span><span class="hljs-params">(String value)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-string">"来源于字母流:"</span> + value;<br>            &#125;<br>        &#125;);<br><br>        result.print();<br><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>运行截图：  </p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_21-05-20.png" srcset="/img/loading.gif" lazyload></p>
<p>上面的代码中，ConnectedStreams 有两个类型参数，分别表示内部包含的两条流各自的数据类型；由于需要“一国两制”，因此调用 <code>.map()</code> 方法时传入的不再是一个简单的 MapFunction，而是一个 CoMapFunction，表示分别对两条流中的数据执行 map 操作。这个接口有三个类型参数，依次表示第一条流、第二条流，以及合并后的流中的数据类型。需要实现的方法也非常直白：<code>.map1()</code> 就是对第一条流中数据的 map 操作，<code>.map2()</code> 则是针对第二条流。</p>
<p>2、CoProcessFunction</p>
<p>与 CoMapFunction 类似，如果是调用 <code>.map()</code> 就需要传入一个 CoMapFunction，需要实现 <code>map1()</code>、<code>map2()</code> 两个方法；而调用 <code>.process()</code> 时，传入的则是一个 CoProcessFunction。它也是“处理函数”家族中的一员，用法非常相似。它需要实现的就是 <code>processElement1()</code>、<code>processElement2()</code> 两个方法，在每个数据到来时，会根据来源的流调用其中的一个方法进行处理。<br>值得一提的是，ConnectedStreams 也可以直接调用 <code>.keyBy()</code> 进行按键分区的操作，得到的还是一个 ConnectedStreams：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">connectedStreams.keyBy(keySelector1, keySelector2);<br></code></pre></td></tr></table></figure>

<p>这里传入两个参数 keySelector1 和 keySelector2，是两条流中各自的键选择器；当然也可以直接传入键的位置值（keyPosition），或者键的字段名（field），这与普通的 keyBy 用法完全一致。ConnectedStreams 进行 keyBy 操作，其实就是把两条流中 key 相同的数据放到了一起，然后针对来源的流再做各自处理，这在一些场景下非常有用。</p>
<p>案例需求：连接两条流，输出能根据 id 匹配上的数据（类似inner join效果）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ConnectKeybyDemo</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br>        env.setParallelism(<span class="hljs-number">2</span>);<br><br>        DataStreamSource&lt;Tuple2&lt;Integer, String&gt;&gt; source1 = env.fromElements(<br>                Tuple2.of(<span class="hljs-number">1</span>, <span class="hljs-string">"a1"</span>),<br>                Tuple2.of(<span class="hljs-number">1</span>, <span class="hljs-string">"a2"</span>),<br>                Tuple2.of(<span class="hljs-number">2</span>, <span class="hljs-string">"b"</span>),<br>                Tuple2.of(<span class="hljs-number">3</span>, <span class="hljs-string">"c"</span>)<br>        );<br>        DataStreamSource&lt;Tuple3&lt;Integer, String, Integer&gt;&gt; source2 = env.fromElements(<br>                Tuple3.of(<span class="hljs-number">1</span>, <span class="hljs-string">"aa1"</span>, <span class="hljs-number">1</span>),<br>                Tuple3.of(<span class="hljs-number">1</span>, <span class="hljs-string">"aa2"</span>, <span class="hljs-number">2</span>),<br>                Tuple3.of(<span class="hljs-number">2</span>, <span class="hljs-string">"bb"</span>, <span class="hljs-number">1</span>),<br>                Tuple3.of(<span class="hljs-number">3</span>, <span class="hljs-string">"cc"</span>, <span class="hljs-number">1</span>)<br>        );<br><br>        ConnectedStreams&lt;Tuple2&lt;Integer, String&gt;, Tuple3&lt;Integer, String, Integer&gt;&gt; connect = source1.connect(source2);<br><br>        <span class="hljs-comment">// 多并行度下，需要根据 关联条件 进行 keyby，才能保证 key 相同的数据到一起去，才能匹配上</span><br>        ConnectedStreams&lt;Tuple2&lt;Integer, String&gt;, Tuple3&lt;Integer, String, Integer&gt;&gt; connectKey = connect.keyBy(s1 -&gt; s1.f0, s2 -&gt; s2.f0);<br><br>        SingleOutputStreamOperator&lt;String&gt; result = connectKey.process(<br>            <span class="hljs-keyword">new</span> CoProcessFunction&lt;Tuple2&lt;Integer, String&gt;, Tuple3&lt;Integer, String, Integer&gt;, String&gt;() &#123;<br>                <span class="hljs-comment">// 定义 HashMap，缓存来过的数据，key=id，value=list&lt;数据&gt;</span><br>                Map&lt;Integer, List&lt;Tuple2&lt;Integer, String&gt;&gt;&gt; s1Cache = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();<br>                Map&lt;Integer, List&lt;Tuple3&lt;Integer, String, Integer&gt;&gt;&gt; s2Cache = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();<br><br>                <span class="hljs-meta">@Override</span><br>                <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">processElement1</span><span class="hljs-params">(Tuple2&lt;Integer, String&gt; value, Context ctx, Collector&lt;String&gt; out)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>                    Integer id = value.f0;<br>                    <span class="hljs-comment">// TODO 1.来过的s1数据，都存起来</span><br>                    <span class="hljs-keyword">if</span> (!s1Cache.containsKey(id)) &#123;<br>                        <span class="hljs-comment">// 1.1 第一条数据，初始化 value的list，放入 hashmap</span><br>                        List&lt;Tuple2&lt;Integer, String&gt;&gt; s1Values = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();<br>                        s1Values.add(value);<br>                        s1Cache.put(id, s1Values);<br>                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                        <span class="hljs-comment">// 1.2 不是第一条，直接添加到 list中</span><br>                        s1Cache.get(id).add(value);<br>                    &#125;<br><br>                    <span class="hljs-comment">//TODO 2.根据id，查找s2的数据，只输出 匹配上 的数据</span><br>                    <span class="hljs-keyword">if</span> (s2Cache.containsKey(id)) &#123;<br>                        <span class="hljs-keyword">for</span> (Tuple3&lt;Integer, String, Integer&gt; s2Element : s2Cache.get(id)) &#123;<br>                            out.collect(<span class="hljs-string">"s1:"</span> + value + <span class="hljs-string">"&lt;---------&gt;s2:"</span> + s2Element);<br>                        &#125;<br>                    &#125;<br>                &#125;<br><br>                <span class="hljs-meta">@Override</span><br>                <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">processElement2</span><span class="hljs-params">(Tuple3&lt;Integer, String, Integer&gt; value, Context ctx, Collector&lt;String&gt; out)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>                    Integer id = value.f0;<br>                    <span class="hljs-comment">// TODO 1.来过的s2数据，都存起来</span><br>                    <span class="hljs-keyword">if</span> (!s2Cache.containsKey(id)) &#123;<br>                        <span class="hljs-comment">// 1.1 第一条数据，初始化 value的list，放入 hashmap</span><br>                        List&lt;Tuple3&lt;Integer, String, Integer&gt;&gt; s2Values = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();<br>                        s2Values.add(value);<br>                        s2Cache.put(id, s2Values);<br>                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                        <span class="hljs-comment">// 1.2 不是第一条，直接添加到 list中</span><br>                        s2Cache.get(id).add(value);<br>                    &#125;<br><br>                    <span class="hljs-comment">//TODO 2.根据id，查找s1的数据，只输出 匹配上 的数据</span><br>                    <span class="hljs-keyword">if</span> (s1Cache.containsKey(id)) &#123;<br>                        <span class="hljs-keyword">for</span> (Tuple2&lt;Integer, String&gt; s1Element : s1Cache.get(id)) &#123;<br>                            out.collect(<span class="hljs-string">"s1:"</span> + s1Element + <span class="hljs-string">"&lt;---------&gt;s2:"</span> + value);<br>                        &#125;<br>                    &#125;<br>                &#125;<br>            &#125;);<br><br>        result.print();<br><br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>运行截图：<br><img src="/img/flink/00/Snipaste_2023-06-07_21-12-12.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="4、输出算子（Sink）"><a href="#4、输出算子（Sink）" class="headerlink" title="4、输出算子（Sink）"></a>4、输出算子（Sink）</h1><p>Flink 作为数据处理框架，最终还是要把计算处理的结果写入外部储存，为外部应用提供支持。  </p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_21-12-13.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="4-1、连接到外部系统"><a href="#4-1、连接到外部系统" class="headerlink" title="4.1、连接到外部系统"></a>4.1、连接到外部系统</h2><p>Flink 的 DataStream API 专门提供了向外部提供写入数据的方法：addSink。与 addSource 类似，addSink 方法对应着一个“Sink”算子，主要就是用来实现与外部系统连接、并将数据提交写入的。Flink 程序中所有对外的输出操作，一般都是利用 Sink 算子完成的。  </p>
<p>Flink1.12 以前，Sink 算子的创建是通过调用 DataStream 的 <code>.addSink()</code> 方法实现的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">stream.addSink(<span class="hljs-keyword">new</span> SinkFunction(…));<br></code></pre></td></tr></table></figure>

<p>addSink 方法同样需要传入一个参数，实现的是 SinkFunction 接口。在这个接口中只需要重写一个方法 invoke()，用来将指定的值写入到外部系统中。这个方法在每条数据记录到来时都会调用。</p>
<p>Flink1.12 开始，同样重构了Sink架构，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">stream.sinkTo(…)<br></code></pre></td></tr></table></figure>

<p>当然，Sink 多数情况下同样并不需要我们自己实现。之前我们一直在使用的 print 方法其实就是一种 Sink，它表示将数据流写入标准控制台打印输出。Flink 官方为我们提供了一部分的框架的 Sink 连接器。如下图所示，列出了 Flink 官方目前支持的第三方系统连接器：</p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_21-12-14.png" srcset="/img/loading.gif" lazyload>  </p>
<p>我们可以看到，像 Kafka 之类流式系统，Flink 提供了完美对接，source&#x2F;sink 两端都能连接，可读可写；而对于 Elasticsearch、JDBC 等数据存储系统，则只提供了输出写入的 sink 连接器。</p>
<p>除 Flink 官方之外，Apache Bahir 框架，也实现了一些其他第三方系统与 Flink 的连接器。  </p>
<p><img src="/img/flink/00/Snipaste_2023-06-07_21-12-15.png" srcset="/img/loading.gif" lazyload>  </p>
<p>除此以外，就需要用户自定义实现 sink 连接器了。</p>
<h2 id="4-2、输出到文件"><a href="#4-2、输出到文件" class="headerlink" title="4.2、输出到文件"></a>4.2、输出到文件</h2><p>Flink 专门提供了一个流式文件系统的连接器：FileSink，为批处理和流处理提供了一个统一的 Sink，它可以将分区文件写入 Flink 支持的文件系统。  </p>
<p>FileSink 支持行编码（Row-encoded）和批量编码（Bulk-encoded）格式。这两种不同的方式都有各自的构建器（builder），可以直接调用 FileSink 的静态方法：</p>
<ul>
<li>行编码： FileSink.forRowFormat（basePath，rowEncoder）。</li>
<li>批量编码： FileSink.forBulkFormat（basePath，bulkWriterFactory）。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SinkFile</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br><br>        <span class="hljs-comment">// 每个目录中，都有 并行度个数的 文件在写入</span><br>        env.setParallelism(<span class="hljs-number">2</span>);<br><br>        <span class="hljs-comment">// 必须开启checkpoint，否则一直都是 .inprogress</span><br>        env.enableCheckpointing(<span class="hljs-number">2000</span>, CheckpointingMode.EXACTLY_ONCE);<br><br><br>        DataGeneratorSource&lt;String&gt; dataGeneratorSource = <span class="hljs-keyword">new</span> DataGeneratorSource&lt;&gt;(<br>                <span class="hljs-keyword">new</span> GeneratorFunction&lt;Long, String&gt;() &#123;<br>                    <span class="hljs-meta">@Override</span><br>                    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">map</span><span class="hljs-params">(Long value)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>                        <span class="hljs-keyword">return</span> <span class="hljs-string">"Number:"</span> + value;<br>                    &#125;<br>                &#125;,<br>                Long.MAX_VALUE,<br>                RateLimiterStrategy.perSecond(<span class="hljs-number">1000</span>),<br>                Types.STRING<br>        );<br><br>        DataStreamSource&lt;String&gt; dataGen = env.fromSource(dataGeneratorSource, WatermarkStrategy.noWatermarks(), <span class="hljs-string">"data-generator"</span>);<br><br>        <span class="hljs-comment">// 输出到文件系统</span><br>        FileSink&lt;String&gt; fieSink = FileSink<br>                <span class="hljs-comment">// 输出行式存储的文件，指定路径、指定编码</span><br>                .&lt;String&gt;forRowFormat(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">"f:/tmp"</span>), <span class="hljs-keyword">new</span> SimpleStringEncoder&lt;&gt;(<span class="hljs-string">"UTF-8"</span>))<br>                <span class="hljs-comment">// 输出文件的一些配置： 文件名的前缀、后缀</span><br>                .withOutputFileConfig(<br>                        OutputFileConfig.builder()<br>                                .withPartPrefix(<span class="hljs-string">"atguigu-"</span>)<br>                                .withPartSuffix(<span class="hljs-string">".log"</span>)<br>                                .build()<br>                )<br>                <span class="hljs-comment">// 按照目录分桶：如下，就是每个小时一个目录</span><br>                .withBucketAssigner(<span class="hljs-keyword">new</span> DateTimeBucketAssigner&lt;&gt;(<span class="hljs-string">"yyyy-MM-dd HH"</span>, ZoneId.systemDefault()))<br>                <span class="hljs-comment">// 文件滚动策略:  1分钟 或 1m</span><br>                .withRollingPolicy(<br>                        DefaultRollingPolicy.builder()<br>                                .withRolloverInterval(Duration.ofMinutes(<span class="hljs-number">1</span>))<br>                                .withMaxPartSize(<span class="hljs-keyword">new</span> MemorySize(<span class="hljs-number">1024</span>*<span class="hljs-number">1024</span>))<br>                                .build()<br>                )<br>                .build();<br>                <br>        dataGen.sinkTo(fieSink);<br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>


<h2 id="4-3、输出到-Kafka"><a href="#4-3、输出到-Kafka" class="headerlink" title="4.3、输出到 Kafka"></a>4.3、输出到 Kafka</h2><ol>
<li><p>添加 Kafka 连接器依赖  </p>
<p>由于我们已经测试过从 Kafka 数据源读取数据，连接器相关依赖已经引入，这里就不重复介绍了。  </p>
</li>
<li><p>启动 Kafka 集群  </p>
</li>
<li><p>编写输出到 Kafka 的示例代码</p>
</li>
</ol>
<p>输出无 key 的 record:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SinkKafka</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br>        env.setParallelism(<span class="hljs-number">1</span>);<br><br>        <span class="hljs-comment">// 如果是精准一次，必须开启checkpoint（后续章节介绍）</span><br>        env.enableCheckpointing(<span class="hljs-number">2000</span>, CheckpointingMode.EXACTLY_ONCE);<br><br>        SingleOutputStreamOperator&lt;String&gt; sensorDS = env<br>                .socketTextStream(<span class="hljs-string">"hadoop102"</span>, <span class="hljs-number">7777</span>);<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * Kafka Sink:</span><br><span class="hljs-comment">         * TODO 注意：如果要使用 精准一次 写入Kafka，需要满足以下条件，缺一不可</span><br><span class="hljs-comment">         * 1、开启checkpoint（后续介绍）</span><br><span class="hljs-comment">         * 2、设置事务前缀</span><br><span class="hljs-comment">         * 3、设置事务超时时间：   checkpoint间隔 &lt;  事务超时时间  &lt; max的15分钟</span><br><span class="hljs-comment">         */</span><br>        KafkaSink&lt;String&gt; kafkaSink = KafkaSink.&lt;String&gt;builder()<br>                <span class="hljs-comment">// 指定 kafka 的地址和端口</span><br>                .setBootstrapServers(<span class="hljs-string">"hadoop102:9092,hadoop103:9092,hadoop104:9092"</span>)<br>                <span class="hljs-comment">// 指定序列化器：指定Topic名称、具体的序列化</span><br>                .setRecordSerializer(<br>                        KafkaRecordSerializationSchema.&lt;String&gt;builder()<br>                                .setTopic(<span class="hljs-string">"ws"</span>)<br>                                .setValueSerializationSchema(<span class="hljs-keyword">new</span> SimpleStringSchema())<br>                                .build()<br>                )<br>                <span class="hljs-comment">// 写到kafka的一致性级别： 精准一次、至少一次</span><br>                .setDeliveryGuarantee(DeliveryGuarantee.EXACTLY_ONCE)<br>                <span class="hljs-comment">// 如果是精准一次，必须设置 事务的前缀</span><br>                .setTransactionalIdPrefix(<span class="hljs-string">"atguigu-"</span>)<br>                <span class="hljs-comment">// 如果是精准一次，必须设置 事务超时时间: 大于checkpoint间隔，小于 max 15分钟</span><br>                .setProperty(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, <span class="hljs-number">10</span>*<span class="hljs-number">60</span>*<span class="hljs-number">1000</span>+<span class="hljs-string">""</span>)<br>                .build();<br><br>        sensorDS.sinkTo(kafkaSink);<br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>自定义序列化器，实现带 key 的 record:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SinkKafkaWithKey</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br>        env.setParallelism(<span class="hljs-number">1</span>);<br><br>        env.enableCheckpointing(<span class="hljs-number">2000</span>, CheckpointingMode.EXACTLY_ONCE);<br>        env.setRestartStrategy(RestartStrategies.noRestart());<br><br><br>        SingleOutputStreamOperator&lt;String&gt; sensorDS = env<br>                .socketTextStream(<span class="hljs-string">"hadoop102"</span>, <span class="hljs-number">7777</span>);<br><br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * 如果要指定写入kafka的key，可以自定义序列化器：</span><br><span class="hljs-comment">         * 1、实现 一个接口，重写 序列化 方法</span><br><span class="hljs-comment">         * 2、指定key，转成 字节数组</span><br><span class="hljs-comment">         * 3、指定value，转成 字节数组</span><br><span class="hljs-comment">         * 4、返回一个 ProducerRecord对象，把key、value放进去</span><br><span class="hljs-comment">         */</span><br>        KafkaSink&lt;String&gt; kafkaSink = KafkaSink.&lt;String&gt;builder()<br>                .setBootstrapServers(<span class="hljs-string">"hadoop102:9092,hadoop103:9092,hadoop104:9092"</span>)<br>                .setRecordSerializer(<br>                        <span class="hljs-keyword">new</span> KafkaRecordSerializationSchema&lt;String&gt;() &#123;<br>                            <span class="hljs-meta">@Nullable</span><br>                            <span class="hljs-meta">@Override</span><br>                            <span class="hljs-keyword">public</span> ProducerRecord&lt;<span class="hljs-keyword">byte</span>[], <span class="hljs-keyword">byte</span>[]&gt; serialize(String element, KafkaSinkContext context, Long timestamp) &#123;<br>                                String[] datas = element.split(<span class="hljs-string">","</span>);<br>                                <span class="hljs-keyword">byte</span>[] key = datas[<span class="hljs-number">0</span>].getBytes(StandardCharsets.UTF_8);<br>                                <span class="hljs-keyword">byte</span>[] value = element.getBytes(StandardCharsets.UTF_8);<br>                                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> ProducerRecord&lt;&gt;(<span class="hljs-string">"ws"</span>, key, value);<br>                            &#125;<br>                        &#125;<br>                )<br>                .setDeliveryGuarantee(DeliveryGuarantee.EXACTLY_ONCE)<br>                .setTransactionalIdPrefix(<span class="hljs-string">"atguigu-"</span>)<br>                .setProperty(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, <span class="hljs-number">10</span> * <span class="hljs-number">60</span> * <span class="hljs-number">1000</span> + <span class="hljs-string">""</span>)<br>                .build();<br><br>        sensorDS.sinkTo(kafkaSink);<br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>运行代码，在 Linux 主机启动一个消费者，查看是否收到数据</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic ws<br></code></pre></td></tr></table></figure>


<h2 id="4-4、输出到-MySQL（JDBC）"><a href="#4-4、输出到-MySQL（JDBC）" class="headerlink" title="4.4、输出到 MySQL（JDBC）"></a>4.4、输出到 MySQL（JDBC）</h2><ol>
<li><p>添加依赖</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java">&lt;!--mysql驱动 --&gt;<br>&lt;dependency&gt;<br>    &lt;groupId&gt;mysql&lt;/groupId&gt;<br>    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;<br>    &lt;version&gt;8.0.27&lt;/version&gt;<br>&lt;/dependency&gt;<br>&lt;dependency&gt;<br>    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;<br>    &lt;artifactId&gt;flink-connector-jdbc&lt;/artifactId&gt;<br>    &lt;version&gt;3.1.0-1.17&lt;/version&gt;<br>&lt;/dependency&gt;<br></code></pre></td></tr></table></figure>
</li>
<li><p>启动 MySQL，在 test 库下建表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> <span class="hljs-string">`ws`</span> (<br>  <span class="hljs-string">`id`</span> <span class="hljs-built_in">varchar</span>(<span class="hljs-number">100</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-string">`ts`</span> <span class="hljs-built_in">bigint</span>(<span class="hljs-number">20</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-string">`vc`</span> <span class="hljs-built_in">int</span>(<span class="hljs-number">11</span>) <span class="hljs-keyword">DEFAULT</span> <span class="hljs-literal">NULL</span>,<br>  PRIMARY <span class="hljs-keyword">KEY</span> (<span class="hljs-string">`id`</span>)<br>) <span class="hljs-keyword">ENGINE</span>=<span class="hljs-keyword">InnoDB</span> <span class="hljs-keyword">DEFAULT</span> <span class="hljs-keyword">CHARSET</span>=utf8<br></code></pre></td></tr></table></figure>
</li>
<li><p>输出到 MySQL 的示例代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SinkMySQL</span> </span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br>        env.setParallelism(<span class="hljs-number">1</span>);<br><br>        SingleOutputStreamOperator&lt;WaterSensor&gt; sensorDS = env<br>                .socketTextStream(<span class="hljs-string">"hadoop102"</span>, <span class="hljs-number">7777</span>)<br>                .map(<span class="hljs-keyword">new</span> WaterSensorMapFunction());<br> <br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * TODO 写入mysql</span><br><span class="hljs-comment">         * 1、只能用老的sink写法： addsink</span><br><span class="hljs-comment">         * 2、JDBCSink的4个参数:</span><br><span class="hljs-comment">         *    第一个参数： 执行的sql，一般就是 insert into</span><br><span class="hljs-comment">         *    第二个参数： 预编译sql， 对占位符填充值</span><br><span class="hljs-comment">         *    第三个参数： 执行选项 ---》 攒批、重试</span><br><span class="hljs-comment">         *    第四个参数： 连接选项 ---》 url、用户名、密码</span><br><span class="hljs-comment">         */</span><br>        SinkFunction&lt;WaterSensor&gt; jdbcSink = JdbcSink.sink(<br>                <span class="hljs-string">"insert into ws values(?,?,?)"</span>,<br>                <span class="hljs-keyword">new</span> JdbcStatementBuilder&lt;WaterSensor&gt;() &#123;<br>                    <span class="hljs-meta">@Override</span><br>                    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">accept</span><span class="hljs-params">(PreparedStatement preparedStatement, WaterSensor waterSensor)</span> <span class="hljs-keyword">throws</span> SQLException </span>&#123;<br>                        <span class="hljs-comment">//每收到一条WaterSensor，如何去填充占位符</span><br>                        preparedStatement.setString(<span class="hljs-number">1</span>, waterSensor.getId());<br>                        preparedStatement.setLong(<span class="hljs-number">2</span>, waterSensor.getTs());<br>                        preparedStatement.setInt(<span class="hljs-number">3</span>, waterSensor.getVc());<br>                    &#125;<br>                &#125;,<br>                JdbcExecutionOptions.builder()<br>                        .withMaxRetries(<span class="hljs-number">3</span>) <span class="hljs-comment">// 重试次数</span><br>                        .withBatchSize(<span class="hljs-number">100</span>) <span class="hljs-comment">// 批次的大小：条数</span><br>                        .withBatchIntervalMs(<span class="hljs-number">3000</span>) <span class="hljs-comment">// 批次的时间</span><br>                        .build(),<br>                <span class="hljs-keyword">new</span> JdbcConnectionOptions.JdbcConnectionOptionsBuilder()<br>                        .withUrl(<span class="hljs-string">"jdbc:mysql://hadoop102:3306/test?serverTimezone=Asia/Shanghai&amp;useUnicode=true&amp;characterEncoding=UTF-8"</span>)<br>                        .withUsername(<span class="hljs-string">"root"</span>)<br>                        .withPassword(<span class="hljs-string">"000000"</span>)<br>                        .withConnectionCheckTimeoutSeconds(<span class="hljs-number">60</span>) <span class="hljs-comment">// 重试的超时时间</span><br>                        .build()<br>        );<br><br>        sensorDS.addSink(jdbcSink);<br>        env.execute();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
</li>
<li><p>运行代码，用客户端连接 MySQL，查看是否成功写入数据。</p>
</li>
</ol>
<h2 id="4-4、自定义-Sink-输出"><a href="#4-4、自定义-Sink-输出" class="headerlink" title="4.4、自定义 Sink 输出"></a>4.4、自定义 Sink 输出</h2><p>如果我们想将数据存储到我们自己的存储设备中，而 Flink 并没有提供可以直接使用的连接器，就只能自定义Sink 进行输出了。与 Source 类似，Flink 为我们提供了通用的 SinkFunction 接口和对应的 RichSinkDunction 抽象类，只要实现它，通过简单地调用 DataStream 的 <code>.addSink()</code> 方法就可以自定义写入任何外部存储。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">stream.addSink(<span class="hljs-keyword">new</span> MySinkFunction&lt;String&gt;());<br></code></pre></td></tr></table></figure>

<p>在实现 SinkFunction 的时候，需要重写的一个关键方法 invoke()，在这个方法中我们就可以实现将流里的数据发送出去的逻辑。<br>这种方式比较通用，对于任何外部存储系统都有效；不过自定义 Sink 想要实现状态一致性并不容易，所以一般只在没有其它选择时使用。实际项目中用到的外部连接器 Flink 官方基本都已实现，而且在不断地扩充，因此自定义的场景并不常见。  </p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Flink/" class="category-chain-item">Flink</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Flink/" class="print-no-link">#Flink</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>06-Flink DateStrame API</div>
      <div>https://flepeng.github.io/045-Flink-31-基础-06-Flink-DateStrame-API/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Lepeng</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2021年3月8日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/081-security-%E6%BC%8F%E6%B4%9E-%E6%BC%8F%E6%B4%9E%E4%B9%8B-XSS%EF%BC%88Cross-Site-Scripting%EF%BC%8C%E8%B7%A8%E7%AB%99%E8%84%9A%E6%9C%AC%E6%94%BB%E5%87%BB%EF%BC%89/" title="漏洞之 XSS（Cross Site Scripting，跨站脚本攻击）">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">漏洞之 XSS（Cross Site Scripting，跨站脚本攻击）</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/049-Git-13-GitHub-GitHub-%E6%90%9C%E7%B4%A2-01-GitHub-%E6%90%9C%E7%B4%A2%E8%AF%AD%E6%B3%95/" title="01-GitHub 搜索语法">
                        <span class="hidden-mobile">01-GitHub 搜索语法</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
    <div id="giscus" class="giscus"></div>
    <script type="text/javascript">
      Fluid.utils.loadComments('#giscus', function() {
        var options = {"repo":"flepeng/hexo-blog-comment","repo-id":"R_kgDOL0qaig","category":"Announcements","category-id":"DIC_kwDOL0qais4CfBIv","theme-light":"light","theme-dark":"dark","mapping":"pathname","reactions-enabled":1,"emit-metadata":0,"input-position":"top","lang":"zh-CN"};
        var attributes = {};
        for (let option in options) {
          if (!option.startsWith('theme-')) {
            var key = option.startsWith('data-') ? option : 'data-' + option;
            attributes[key] = options[option];
          }
        }
        var light = 'light';
        var dark = 'dark';
        window.GiscusThemeLight = light;
        window.GiscusThemeDark = dark;
        attributes['data-theme'] = document.documentElement.getAttribute('data-user-color-scheme') === 'dark' ? dark : light;
        for (let attribute in attributes) {
          var value = attributes[attribute];
          if (value === undefined || value === null || value === '') {
            delete attributes[attribute];
          }
        }
        var s = document.createElement('script');
        s.setAttribute('src', 'https://giscus.app/client.js');
        s.setAttribute('crossorigin', 'anonymous');
        for (let attribute in attributes) {
          s.setAttribute(attribute, attributes[attribute]);
        }
        var ss = document.getElementsByTagName('script');
        var e = ss.length > 0 ? ss[ss.length - 1] : document.head || document.documentElement;
        e.parentNode.insertBefore(s, e.nextSibling);
      });
    </script>
    <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
