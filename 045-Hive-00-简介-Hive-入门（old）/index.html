

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2488174175014870" crossorigin="anonymous"></script><!-- google 广告 -->
  <meta name="google-site-verification" content="40lMg4eqLLbXoDcpN3h-cEnfmselbQ8tUzNvuC0IRIs" /><!-- google 站点认证 -->
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Lepeng">
  <meta name="keywords" content="">
  
    <meta name="description" content="1 Hive 简介1.1 Hive简介1.1.1 什么是 HiveHive是基于Hadoop的数据仓库解决方案。由于Hadoop本身在数据存储和计算方面有很好的可扩展性和高容错性，因此使用Hive构建的数据仓库也秉承了这些特性。 这是来自官方的解释。 Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。可以将sql语句转换为MapRedu">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive 入门（old）">
<meta property="og:url" content="https://flepeng.github.io/045-Hive-00-%E7%AE%80%E4%BB%8B-Hive-%E5%85%A5%E9%97%A8%EF%BC%88old%EF%BC%89/index.html">
<meta property="og:site_name" content="Lepeng">
<meta property="og:description" content="1 Hive 简介1.1 Hive简介1.1.1 什么是 HiveHive是基于Hadoop的数据仓库解决方案。由于Hadoop本身在数据存储和计算方面有很好的可扩展性和高容错性，因此使用Hive构建的数据仓库也秉承了这些特性。 这是来自官方的解释。 Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。可以将sql语句转换为MapRedu">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://flepeng.github.io/img/hive/Hive%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg">
<meta property="og:image" content="https://flepeng.github.io/img/hive/Hive%E8%BF%90%E8%A1%8C%E5%9B%BE.jpg">
<meta property="og:image" content="https://flepeng.github.io/img/hive/1617015424-c1c2af6201e88323bec8e5712aa1aab8.png">
<meta property="og:image" content="https://flepeng.github.io/img/hive/1617015424-b2a3af727a48b1c2208d456dab63a042.png">
<meta property="article:published_time" content="2024-12-31T16:00:00.000Z">
<meta property="article:modified_time" content="2025-04-03T10:25:30.405Z">
<meta property="article:author" content="Feng Lepeng">
<meta property="article:tag" content="Hive">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://flepeng.github.io/img/hive/Hive%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Hive 入门（old） - Lepeng</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"flepeng.github.io","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":"f3d259b9efd9ce8655c180fd01bf0045","google":{"measurement_id":"G-LFTE4C7W3W"},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  
    <!-- Baidu Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?f3d259b9efd9ce8655c180fd01bf0045";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
      }
    </script>
  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=G-LFTE4C7W3W", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', 'G-LFTE4C7W3W');
        });
      }
    </script>
  

  

  

  

  



  
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Lepeng 的 blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Hive 入门（old）"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-01-01 00:00" pubdate>
          2025年1月1日 凌晨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          7.6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          63 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Hive 入门（old）</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="1-Hive-简介"><a href="#1-Hive-简介" class="headerlink" title="1 Hive 简介"></a>1 Hive 简介</h1><h2 id="1-1-Hive简介"><a href="#1-1-Hive简介" class="headerlink" title="1.1 Hive简介"></a>1.1 Hive简介</h2><h3 id="1-1-1-什么是-Hive"><a href="#1-1-1-什么是-Hive" class="headerlink" title="1.1.1 什么是 Hive"></a>1.1.1 什么是 Hive</h3><p>Hive是基于Hadoop的数据仓库解决方案。由于Hadoop本身在数据存储和计算方面有很好的可扩展性和高容错性，因此使用Hive构建的数据仓库也秉承了这些特性。</p>
<p>这是来自官方的解释。</p>
<p>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。可以将sql语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。Hive是一个数据仓库基础工具在Hadoop中用来处理结构化数据。它架构在Hadoop之上，总归为大数据，并使得查询和分析方便。</p>
<p>在Hive中，Hive是SQL解析引擎，它将SQL语句转译成M&#x2F;R Job然后在Hadoop执行。Hive的表其实就是HDFS的目录&#x2F;文件，按表名把文件夹分开。如果是分区表，则分区值是子文件夹，可以直接在M&#x2F;RJob里使用这些数据。</p>
<p>简单来说，Hive就是在Hadoop上架了一层SQL接口，可以将SQL翻译成MapReduce去Hadoop上执行，这样就使得数据开发和分析人员很方便的使用SQL来完成海量数据的统计和分析，而不必使用编程语言开发MapReduce那么麻烦。</p>
<p>最初，Hive是由Facebook开发，后来由Apache软件基金会开发，并作为进一步将它作为名义下ApacheHive为一个开源项目。它用在好多不同的公司。例如，亚马逊使用它在Amazon Elastic、MapReduce。 </p>
<h3 id="1-1-2-为什么使用Hive"><a href="#1-1-2-为什么使用Hive" class="headerlink" title="1.1.2 为什么使用Hive"></a>1.1.2 为什么使用Hive</h3><ol>
<li>直接使用hadoop所面临的问题</li>
</ol>
<p>  人员学习成本太高<br>  项目周期要求太短<br>  MapReduce实现复杂查询逻辑开发难度太大</p>
<ol start="2">
<li>操作接口采用类SQL语法，提供快速开发的能力。</li>
</ol>
<p>  避免了去写MapReduce，减少开发人员的学习成本。<br>  扩展功能很方便。</p>
<h3 id="1-1-3-Hive的特点"><a href="#1-1-3-Hive的特点" class="headerlink" title="1.1.3 Hive的特点"></a>1.1.3 Hive的特点</h3><ol>
<li>可扩展</li>
</ol>
<p>  Hive可以自由的扩展集群的规模，一般情况下不需要重启服务。</p>
<ol start="2">
<li>延展性</li>
</ol>
<p> Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</p>
<ol start="3">
<li>容错</li>
</ol>
<p>  良好的容错性，节点出现问题SQL仍可完成执行。</p>
<h3 id="1-1-4-Hive擅长什么"><a href="#1-1-4-Hive擅长什么" class="headerlink" title="1.1.4 Hive擅长什么"></a>1.1.4 Hive擅长什么</h3><p>Hive可以使用HQL(Hive SQL)很方便的完成对海量数据的统计汇总，即席查询和分析，除了很多内置的函数，还支持开发人员使用其他编程语言和脚本语言来自定义函数。</p>
<p>但是，由于Hadoop本身是一个批处理，高延迟的计算框架，Hive使用Hadoop作为执行引擎，自然也就有了批处理，高延迟的特点，在数据量很小的时候，Hive执行也需要消耗较长时间来完成，这时候，就显示不出它与Oracle，Mysql等传统数据库的优势。</p>
<p>此外，Hive对事物的支持不够好，原因是HDFS本身就设计为一次写入，多次读取的分布式存储系统，因此，不能使用Hive来完成诸如DELETE、UPDATE等在线事务处理的需求。</p>
<p>因此，Hive擅长的是非实时的、离线的、对响应及时性要求不高的海量数据批量计算，即席查询，统计分析。</p>
<h2 id="1-2-Hive架构"><a href="#1-2-Hive架构" class="headerlink" title="1.2 Hive架构"></a>1.2 Hive架构</h2><h3 id="1-2-1-架构图"><a href="#1-2-1-架构图" class="headerlink" title="1.2.1 架构图"></a>1.2.1 架构图</h3><p> <img src="/img/hive/Hive%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" srcset="/img/loading.gif" lazyload> </p>
<p>Jobtracker 是 hadoop1.x 中的组件，它的功能相当于：Resourcemanager+AppMaster</p>
<p>TaskTracker 相当于： Nodemanager + yarnchild</p>
<h3 id="1-2-2-基本组成"><a href="#1-2-2-基本组成" class="headerlink" title="1.2.2 基本组成"></a>1.2.2 基本组成</h3><ol>
<li><p>用户接口：包括 CLI、JDBC&#x2F;ODBC、WebGUI。其中，CLI为shell命令行；JDBC&#x2F;ODBC是Hive的JAVA实现，与传统数据库JDBC类似；WebGUI是通过浏览器访问Hive。</p>
</li>
<li><p>元数据存储：Hive 将元数据存储在关系数据库如 mysql , derby中。Hive 中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。</p>
</li>
<li><p>解释器、编译器、优化器、执行器。解释器、编译器、优化器完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后有 MapReduce 调用执行。</p>
</li>
<li><p>Hive 的数据存储在 HDFS 中，大部分的查询由 MapReduce 完成（包含 * 的查询，比如 select * from table 不会生成 MapRedcue 任务）</p>
</li>
<li><p>Thrift是一个软件框架，用来进行可扩展且跨语言的服务的开发。它结合了功能强大的软件堆栈和代码生成引擎，以构建在 C++,Java, Go,Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript,Node.js, Smalltalk, and OCaml这些编程语言间无缝结合的、高效的服务。</p>
</li>
</ol>
<h3 id="1-2-3-Metastore组件"><a href="#1-2-3-Metastore组件" class="headerlink" title="1.2.3 Metastore组件:"></a>1.2.3 Metastore组件:</h3><p>Hive的Metastore组件是Hive元数据集中存放地。Metastore组件包括两个部分：Metastore服务和后台数据的存储。后台数据存储的介质就是关系数据库，例如Hive默认的嵌入式磁盘数据库derby，还有mysql数据库。Metastore服务是建立在后台数据存储介质之上，并且可以和Hive服务进行交互的服务组件，默认情况下，Metastore服务和Hive服务是安装在一起的，运行在同一个进程当中。我也可以把Metastore服务从Hive服务里剥离出来，Metastore独立安装在一个集群里，Hive远程调用Metastore服务，这样我们可以把元数据这一层放到防火墙之后，客户端访问Hive服务，就可以连接到元数据这一层，从而提供了更好的管理性和安全保障。使用远程的Metastore服务，可以让Metastore服务和hive服务运行在不同的进程里，这样也保证了Hive的稳定性，提升了Hive服务的效率。</p>
<h3 id="1-2-4-Hive的执行流程"><a href="#1-2-4-Hive的执行流程" class="headerlink" title="1.2.4 Hive的执行流程"></a>1.2.4 Hive的执行流程</h3><p>如下图所示：<br> <img src="/img/hive/Hive%E8%BF%90%E8%A1%8C%E5%9B%BE.jpg" srcset="/img/loading.gif" lazyload> </p>
<h2 id="1-3-Hive与Hadoop的关系"><a href="#1-3-Hive与Hadoop的关系" class="headerlink" title="1.3 Hive与Hadoop的关系"></a>1.3 Hive与Hadoop的关系</h2><p>Hive利用HDFS存储数据，利用MapReduce查询数据</p>
<p><img src="/img/hive/1617015424-c1c2af6201e88323bec8e5712aa1aab8.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="1-4-Hive与传统数据库对比"><a href="#1-4-Hive与传统数据库对比" class="headerlink" title="1.4 Hive与传统数据库对比"></a>1.4 Hive与传统数据库对比</h2><p>如下所示：</p>
<table>
<thead>
<tr>
<th></th>
<th>Hive</th>
<th>RDBMS</th>
</tr>
</thead>
<tbody><tr>
<td>查询语言</td>
<td>HiveQL</td>
<td>SQL</td>
</tr>
<tr>
<td>数据存储位置</td>
<td>HDFS</td>
<td>Raw  Device or 本地FS</td>
</tr>
<tr>
<td>数据格式</td>
<td>用户定义</td>
<td>系统决定</td>
</tr>
<tr>
<td>数据更新</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>索引</td>
<td>0.8 版本加入位图索引，但弱</td>
<td>有</td>
</tr>
<tr>
<td>执行</td>
<td>MapReduce</td>
<td>Executor</td>
</tr>
<tr>
<td>执行延迟</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>可扩展性</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>数据规模</td>
<td>大</td>
<td>小</td>
</tr>
</tbody></table>
<p>总结：hive具有sql数据库的外表，但应用场景完全不同，hive只适合用来做批量数据统计分析_</p>
<h2 id="1-5-Hive的数据存储"><a href="#1-5-Hive的数据存储" class="headerlink" title="1.5 Hive的数据存储"></a>1.5 Hive的数据存储</h2><ol>
<li><p>Hive中所有的数据都存储在 HDFS 中，没有专门的数据存储格式（可支持Text，SequenceFile，ParquetFile，RCFILE等）</p>
</li>
<li><p>只需要在创建表的时候告诉 Hive 数据中的列分隔符和行分隔符，Hive 就可以解析数据。</p>
</li>
<li><p>Hive 中包含以下数据模型：DB、Table，External Table，Partition，Bucket。</p>
</li>
</ol>
<ul>
<li><p>db：在hdfs中表现为${hive.metastore.warehouse.dir}目录下一个文件夹</p>
</li>
<li><p>table：在hdfs中表现所属db目录下一个文件夹</p>
</li>
<li><p>external table：外部表, 与table类似，不过其数据存放位置可以在任意指定路径</p>
<ul>
<li><p>普通表: 删除表后, hdfs上的文件都删了</p>
</li>
<li><p>External外部表删除后, hdfs上的文件没有删除, 只是把文件删除了</p>
</li>
</ul>
</li>
<li><p>partition：在hdfs中表现为table目录下的子目录</p>
</li>
<li><p>bucket：桶, 在hdfs中表现为同一个表目录下根据hash散列之后的多个文件, 会根据不同的文件把数据放到不同的文件中</p>
</li>
</ul>
<h2 id="1-6-HIVE的安装部署"><a href="#1-6-HIVE的安装部署" class="headerlink" title="1.6 HIVE的安装部署"></a>1.6 HIVE的安装部署</h2><h3 id="1-6-1-安装"><a href="#1-6-1-安装" class="headerlink" title="1.6.1 安装"></a>1.6.1 安装</h3><p>Hive是建立Hadoop环境安装之上的，所以需要Hadoop的集群环境搭建，Hive即需要依赖于HDFS又需要依赖YARN。安装好Hadoop后需要进行启动HDFS和YARN。<br>TODO</p>
<h3 id="1-6-2-使用方式"><a href="#1-6-2-使用方式" class="headerlink" title="1.6.2 使用方式"></a>1.6.2 使用方式</h3><h4 id="Hive交互shell"><a href="#Hive交互shell" class="headerlink" title="Hive交互shell"></a>Hive交互shell</h4><p>bin&#x2F;hive</p>
<h4 id="Hive-thrift服务"><a href="#Hive-thrift服务" class="headerlink" title="Hive thrift服务"></a>Hive thrift服务</h4><p> <img src="/img/hive/1617015424-b2a3af727a48b1c2208d456dab63a042.png" srcset="/img/loading.gif" lazyload></p>
<p>启动方式，（假如是在hadoop01上）：</p>
<p>启动为前台：bin&#x2F;hiveserver2</p>
<p>启动为后台：nohup bin&#x2F;hiveserver2 1&gt;&#x2F;var&#x2F;log&#x2F;hiveserver.log 2&gt;&#x2F;var&#x2F;log&#x2F;hiveserver.err &amp;</p>
<p>启动成功后，可以在别的节点上用beeline去连接</p>
<p>v 方式（1）</p>
<p>hive&#x2F;bin&#x2F;beeline  回车，进入beeline的命令界面</p>
<p>输入命令连接hiveserver2</p>
<p>beeline&gt; !connect jdbc:hive2&#x2F;&#x2F;mini1:10000</p>
<p>（hadoop01是hiveserver2所启动的那台主机名，端口默认是10000）</p>
<p>v 方式（2）</p>
<p>或者启动就连接：</p>
<p><strong>bin&#x2F;beeline -u jdbc:hive2:&#x2F;&#x2F;hadoop01:10000 -n hadoop</strong></p>
<p>接下来就可以做正常sql查询了</p>
<h4 id="Hive命令"><a href="#Hive命令" class="headerlink" title="Hive命令"></a>Hive命令</h4><p>[hadoop@hdp-node-02 ~]$ hive  -e  ‘sql’</p>
<h2 id="1-7-Hive的shell"><a href="#1-7-Hive的shell" class="headerlink" title="1.7  Hive的shell"></a>1.7  Hive的shell</h2><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-number">1</span>、hive 命令行模式，直接输入#/hive/bin/hive的执行程序，或者输入#hive --service cli<br><br><span class="hljs-number">2</span>、 hive web界面的 (端口号<span class="hljs-number">9999</span>) 启动方式<br><br>#hive --service hwi&amp;<br><br>用于通过浏览器来访问hive<br><br>http:<span class="hljs-comment">//hadoop0:9999/hwi/</span><br><br><span class="hljs-number">3</span>、 hive 远程服务 (端口号<span class="hljs-number">10000</span>) 启动方式<br><br>#hive --service hiveserver&amp;<br></code></pre></td></tr></table></figure>

<h2 id="1-8-HIVE和HBASE区别"><a href="#1-8-HIVE和HBASE区别" class="headerlink" title="1.8  HIVE和HBASE区别"></a>1.8  HIVE和HBASE区别</h2><ol>
<li>两者分别是什么？</li>
</ol>
<p> Apache Hive是一个构建在Hadoop基础设施之上的数据仓库。通过Hive可以使用HQL语言查询存放在HDFS上的数据。HQL是一种类SQL语言，这种语言最终被转化为Map&#x2F;Reduce. 虽然Hive提供了SQL查询功能，但是Hive不能够进行交互查询–因为它只能够在Haoop上批量的执行Hadoop。</p>
<p> Apache HBase是一种Key&#x2F;Value系统，它运行在HDFS之上。和Hive不一样，Hbase的能够在它的数据库上实时运行，而不是运行MapReduce任务。Hive被分区为表格，表格又被进一步分割为列簇。列簇必须使用schema定义，列簇将某一类型列集合起来（列不要求schema定义）。例如，“message”列簇可能包含：“to”, ”from” “date”, “subject”, 和”body”. 每一个 key&#x2F;value对在Hbase中被定义为一个cell，每一个key由row-key，列簇、列和时间戳。在Hbase中，行是key&#x2F;value映射的集合，这个映射通过row-key来唯一标识。Hbase利用Hadoop的基础设施，可以利用通用的设备进行水平的扩展。</p>
<ol start="2">
<li>两者的特点：</li>
</ol>
<p>  Hive帮助熟悉SQL的人运行MapReduce任务。因为它是JDBC兼容的，同时，它也能够和现存的SQL工具整合在一起。运行Hive查询会花费很长时间，因为它会默认遍历表中所有的数据。虽然有这样的缺点，一次遍历的数据量可以通过Hive的分区机制来控制。分区允许在数据集上运行过滤查询，这些数据集存储在不同的文件夹内，查询的时候只遍历指定文件夹（分区）中的数据。这种机制可以用来，例如，只处理在某一个时间范围内的文件，只要这些文件名中包括了时间格式。</p>
<p> HBase通过存储key&#x2F;value来工作。它支持四种主要的操作：增加或者更新行，查看一个范围内的cell，获取指定的行，删除指定的行、列或者是列的版本。版本信息用来获取历史数据（每一行的历史数据可以被删除，然后通过Hbase compactions就可以释放出空间）。虽然HBase包括表格，但是schema仅仅被表格和列簇所要求，列不需要schema。Hbase的表格包括增加&#x2F;计数功能。</p>
<ol start="3">
<li>限制</li>
</ol>
<p>  Hive目前不支持更新操作。另外，由于hive在hadoop上运行批量操作，它需要花费很长的时间，通常是几分钟到几个小时才可以获取到查询的结果。Hive必须提供预先定义好的schema将文件和目录映射到列，并且Hive与ACID不兼容。</p>
<p>  HBase查询是通过特定的语言来编写的，这种语言需要重新学习。类SQL的功能可以通过Apache Phonenix实现，但这是以必须提供schema为代价的。另外，Hbase也并不是兼容所有的ACID特性，虽然它支持某些特性。最后但不是最重要的–为了运行Hbase，Zookeeper是必须的，zookeeper是一个用来进行分布式协调的服务，这些服务包括配置服务，维护元信息和命名空间服务。</p>
<ol start="4">
<li>应用场景</li>
</ol>
<p>  Hive适合用来对一段时间内的数据进行分析查询，例如，用来计算趋势或者网站的日志。Hive不应该用来进行实时的查询。因为它需要很长时间才可以返回结果。</p>
<p>  Hbase非常适合用来进行大数据的实时查询。Facebook用Hbase进行消息和实时的分析。它也可以用来统计Facebook的连接数。</p>
<ol start="5">
<li>总结</li>
</ol>
<p>  Hive和Hbase是两种基于Hadoop的不同技术–Hive是一种类SQL的引擎，并且运行MapReduce任务，Hbase是一种在Hadoop之上的NoSQL 的Key&#x2F;vale数据库。当然，这两种工具是可以同时使用的。就像用Google来搜索，用FaceBook进行社交一样，Hive可以用来进行统计查询，HBase可以用来进行实时查询，数据也可以从Hive写到Hbase，设置再从Hbase写回Hive</p>
<h1 id="2-Hive-基本操作"><a href="#2-Hive-基本操作" class="headerlink" title="2 Hive 基本操作"></a>2 Hive 基本操作</h1><h2 id="2-1-Hive-数据类型"><a href="#2-1-Hive-数据类型" class="headerlink" title="2.1 Hive 数据类型"></a>2.1 Hive 数据类型</h2><p>既然是被当做数据库来使用，除了数据单元，Hive当然也得有一些列的数据类型</p>
<h3 id="2-1-1-原始数据类型"><a href="#2-1-1-原始数据类型" class="headerlink" title="2.1.1 原始数据类型"></a>2.1.1 原始数据类型</h3><ol>
<li>整型</li>
</ol>
<ul>
<li>TINYINT — 微整型，只占用1个字节，只能存储0-255的整数。</li>
<li>SMALLINT– 小整型，占用2个字节，存储范围–32768 到 32767。</li>
<li>INT– 整型，占用4个字节，存储范围-2147483648到2147483647。</li>
<li>BIGINT– 长整型，占用8个字节，存储范围-2^63到2^63-1。</li>
</ul>
<ol start="2">
<li>布尔型</li>
</ol>
<ul>
<li>BOOLEAN — TRUE&#x2F;FALSE</li>
</ul>
<ol start="3">
<li>浮点型</li>
</ol>
<ul>
<li>FLOAT– 单精度浮点数。</li>
<li>DOUBLE– 双精度浮点数。</li>
</ul>
<ol start="4">
<li>字符串型</li>
</ol>
<ul>
<li>STRING– 不设定长度。</li>
</ul>
<h3 id="2-1-2-复合数据类型"><a href="#2-1-2-复合数据类型" class="headerlink" title="2.1.2 复合数据类型"></a>2.1.2 复合数据类型</h3><ol>
<li>Structs：一组由任意数据类型组成的结构。比如，定义一个字段C的类型为STRUCT {a INT; b STRING}，则可以使用a和C.b来获取其中的元素值；</li>
<li>Maps：和Java中的Map没什么区别，就是存储K-V对的；</li>
<li>Arrays：就是数组而已；</li>
</ol>
<h2 id="2-1-Hive-交互式模式"><a href="#2-1-Hive-交互式模式" class="headerlink" title="2.1 Hive 交互式模式"></a>2.1 Hive 交互式模式</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sql">quit,exit:  退出交互式shell<br><span class="hljs-keyword">reset</span>: 重置配置为默认值<br><span class="hljs-keyword">set</span> &lt;<span class="hljs-keyword">key</span>&gt;=&lt;<span class="hljs-keyword">value</span>&gt; : 修改特定变量的值(如果变量名拼写错误，不会报错)<br><span class="hljs-keyword">set</span> :  输出用户覆盖的hive配置变量<br><span class="hljs-keyword">set</span> -v : 输出所有Hadoop和Hive的配置变量<br><span class="hljs-keyword">add</span> <span class="hljs-keyword">FILE</span>[S] *, <span class="hljs-keyword">add</span> JAR[S] *, <span class="hljs-keyword">add</span> <span class="hljs-keyword">ARCHIVE</span>[S] * : 添加 一个或多个 <span class="hljs-keyword">file</span>, jar, archives到分布式缓存<br><span class="hljs-keyword">list</span> <span class="hljs-keyword">FILE</span>[S], <span class="hljs-keyword">list</span> JAR[S], <span class="hljs-keyword">list</span> <span class="hljs-keyword">ARCHIVE</span>[S] : 输出已经添加到分布式缓存的资源。<br><span class="hljs-keyword">list</span> <span class="hljs-keyword">FILE</span>[S] *, <span class="hljs-keyword">list</span> JAR[S] *,<span class="hljs-keyword">list</span> <span class="hljs-keyword">ARCHIVE</span>[S] * : 检查给定的资源是否添加到分布式缓存<br><span class="hljs-keyword">delete</span> <span class="hljs-keyword">FILE</span>[S] *,<span class="hljs-keyword">delete</span> JAR[S] *,<span class="hljs-keyword">delete</span> <span class="hljs-keyword">ARCHIVE</span>[S] * : 从分布式缓存删除指定的资源<br>! &lt;command&gt; :  从Hive shell执行一个shell命令<br>dfs &lt;dfs command&gt; :  从Hive shell执行一个dfs命令<br>&lt;<span class="hljs-keyword">query</span> <span class="hljs-keyword">string</span>&gt; : 执行一个Hive 查询，然后输出结果到标准输出<br><span class="hljs-keyword">source</span> <span class="hljs-keyword">FILE</span> &lt;filepath&gt;:  在CLI里执行一个hive脚本文件<br></code></pre></td></tr></table></figure>

<h2 id="2-1-DDL操作"><a href="#2-1-DDL操作" class="headerlink" title="2.1 DDL操作"></a>2.1 DDL操作</h2><h3 id="2-1-1-创建表"><a href="#2-1-1-创建表" class="headerlink" title="2.1.1 创建表"></a>2.1.1 创建表</h3><h4 id="建表语法"><a href="#建表语法" class="headerlink" title="建表语法"></a>建表语法</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> [<span class="hljs-keyword">EXTERNAL</span>] <span class="hljs-keyword">TABLE</span> [<span class="hljs-keyword">IF</span> <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span>] table_name<br>   [(col_name data_type [<span class="hljs-keyword">COMMENT</span> col_comment], ...)]<br>   [<span class="hljs-keyword">COMMENT</span> table_comment]<br>   [PARTITIONED <span class="hljs-keyword">BY</span> (col_name data_type [<span class="hljs-keyword">COMMENT</span> col_comment], ...)] <span class="hljs-comment"># 创建分区</span><br>   [CLUSTERED <span class="hljs-keyword">BY</span> (col_name, col_name, ...) <span class="hljs-comment"># 创建分桶表</span><br>   [SORTED <span class="hljs-keyword">BY</span> (col_name [<span class="hljs-keyword">ASC</span>|<span class="hljs-keyword">DESC</span>], ...)] <span class="hljs-keyword">INTO</span> num_buckets BUCKETS]<br>   [<span class="hljs-keyword">ROW</span> <span class="hljs-keyword">FORMAT</span> row_format] <span class="hljs-comment"># 指定表的分隔符</span><br>   [<span class="hljs-keyword">STORED</span> <span class="hljs-keyword">AS</span> file_format] <br>   [LOCATION hdfs_path]   <span class="hljs-comment"># 指定表的存储位置</span><br></code></pre></td></tr></table></figure>

<p>create table test1(id int, num long)</p>
<p>说明：</p>
<ol>
<li><p>CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。</p>
</li>
<li><p>EXTERNAL关键字可以让用户创建一个外部表，在建表的同时指定一个指向实际数据的路径（LOCATION），Hive 创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。</p>
</li>
<li><p>LIKE 允许用户复制现有的表结构，但是不复制数据。</p>
</li>
<li><p>ROW FORMAT DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char] [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] | SERDE serde_name [WITH SERDEPROPERTIES (property_name&#x3D;property_value, property_name&#x3D;property_value, …)]</p>
</li>
</ol>
<p>  用户在建表的时候可以自定义 SerDe 或者使用自带的 SerDe。如果没有指定 ROW FORMAT 或者 ROW FORMAT DELIMITED，将会使用自带的 SerDe。</p>
<p>  在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的 SerDe，Hive通过 SerDe 确定表的具体的列的数据。</p>
<ol start="5">
<li><p>STORED AS</p>
<p> SEQUENCEFILE|TEXTFILE|RCFILE</p>
<p> 如果文件数据是纯文本，可以使用 STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。</p>
</li>
<li><p>CLUSTERED BY</p>
<p> 对于每一个表（table）或者分区， Hive可以进一步组织成桶，也就是说桶是更为细粒度的数据范围划分。Hive也是 针对某一列进行桶的组织。Hive采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中。</p>
<p> 把表（或者分区）组织成桶（Bucket）有两个理由：</p>
</li>
</ol>
<ul>
<li><p>获得更高的查询处理效率。桶为表加上了额外的结构，Hive 在处理有些查询时能利用这个结构。具体而言，连接两个在（包含连接列的）相同列上划分了桶的表，可以使用 Map 端连接 （Map-side join）高效的实现。比如JOIN操作。对于JOIN操作两个表有一个相同的列，如果对这两个表都进行了桶操作。那么将保存相同列值的桶进行JOIN操作就可以，可以大大较少JOIN的数据量。</p>
</li>
<li><p>使取样（sampling）更高效。在处理大规模数据集时，在开发和修改查询的阶段，如果能在数据集的一小部分数据上试运行查询，会带来很多方便。</p>
</li>
</ul>
<h4 id="具体实例"><a href="#具体实例" class="headerlink" title="具体实例"></a>具体实例</h4><p>创建内部表mytable。</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">hive&gt; <span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">exists</span> mytable(sid <span class="hljs-type">int</span>,sname string)  <br>   &gt; <span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">','</span> <br>    &gt; stored <span class="hljs-keyword">as</span> textfile;<br></code></pre></td></tr></table></figure>

<p>创建外部表pageview。</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">hive&gt; <span class="hljs-keyword">create</span> <span class="hljs-keyword">external</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">exists</span> pageview(  <br>   &gt; pageid <span class="hljs-type">int</span>,<br>   &gt; page_url string <span class="hljs-keyword">comment</span> <span class="hljs-string">'The page URL'</span>)  <br>   &gt; <span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">','</span>  <br>   &gt; <span class="hljs-keyword">location</span> <span class="hljs-string">'hdfs://192.168.158.171:9000/user/hivewarehouse/'</span>;<br></code></pre></td></tr></table></figure>

<p>创建分区表invites。</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">hive&gt; <span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> student_p(  <br>    &gt; Sno <span class="hljs-type">int</span>,  <br>    &gt; Sname string,  <br>    &gt; Sex string,  <br>    &gt; Sage <span class="hljs-type">int</span>,  <br>    &gt; Sdept string)   <br>    &gt; partitioned <span class="hljs-keyword">by</span>(part string)   <br>    &gt; <span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">','</span>stored <span class="hljs-keyword">as</span> textfile;<br></code></pre></td></tr></table></figure>

<p>创建带桶的表student。</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">hive&gt; <span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> student(id <span class="hljs-type">int</span>,age <span class="hljs-type">int</span>,<span class="hljs-type">name</span> string)  <br>   &gt; partitioned <span class="hljs-keyword">by</span>(stat_data string)  <br>   &gt; clustered <span class="hljs-keyword">by</span>(id) sorted <span class="hljs-keyword">by</span>(age) <span class="hljs-keyword">into</span> <span class="hljs-number">2</span> buckets  <br>   &gt; <span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">','</span>;<br></code></pre></td></tr></table></figure>

<h3 id="2-1-2-修改表"><a href="#2-1-2-修改表" class="headerlink" title="2.1.2 修改表"></a>2.1.2 修改表</h3><h4 id="增加-x2F-删除分区"><a href="#增加-x2F-删除分区" class="headerlink" title="增加&#x2F;删除分区"></a>增加&#x2F;删除分区</h4><h5 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> table_name <span class="hljs-keyword">ADD</span> [<span class="hljs-keyword">IF</span> <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span>] partition_spec [ LOCATION <span class="hljs-string">'location1'</span> ] partition_spec [ LOCATION <span class="hljs-string">'location2'</span> ] ...<br><br>partition_spec:<br><br>: <span class="hljs-keyword">PARTITION</span> (partition_col = partition_col_value, partition_col = partiton_col_value, ...)<br><br><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> table_name <span class="hljs-keyword">DROP</span> partition_spec, partition_spec,...<br></code></pre></td></tr></table></figure>

<p>具体实例</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">alter table student_p <span class="hljs-builtin-name">add</span> partition(<span class="hljs-attribute">part</span>=<span class="hljs-string">'a'</span>) partition(<span class="hljs-attribute">part</span>=<span class="hljs-string">'b'</span>);<br></code></pre></td></tr></table></figure>

<h4 id="重命名表"><a href="#重命名表" class="headerlink" title="重命名表"></a>重命名表</h4><h5 id="语法结构"><a href="#语法结构" class="headerlink" title="语法结构"></a>语法结构</h5><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> <span class="hljs-built_in">table_name</span> <span class="hljs-keyword">RENAME</span> <span class="hljs-keyword">TO</span> new_table_name<br></code></pre></td></tr></table></figure>

<h5 id="具体实例-1"><a href="#具体实例-1" class="headerlink" title="具体实例"></a>具体实例</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> student <span class="hljs-keyword">rename</span> <span class="hljs-keyword">to</span> student1;<br></code></pre></td></tr></table></figure>

<h4 id="增加-x2F-更新列"><a href="#增加-x2F-更新列" class="headerlink" title="增加&#x2F;更新列"></a>增加&#x2F;更新列</h4><h5 id="语法结构-1"><a href="#语法结构-1" class="headerlink" title="语法结构"></a>语法结构</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> table_name <span class="hljs-keyword">ADD</span>|<span class="hljs-keyword">REPLACE</span> <span class="hljs-keyword">COLUMNS</span> (col_name data_type [<span class="hljs-keyword">COMMENT</span> col_comment], ...)<br><span class="hljs-comment"># _注：ADD是代表新增一字段，字段位置在所有列后面(partition列前)，REPLACE则是表示替换表中所有字段。_</span><br><br><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> table_name <span class="hljs-keyword">CHANGE</span> [<span class="hljs-keyword">COLUMN</span>] col_old_name col_new_name column_type [<span class="hljs-keyword">COMMENT</span> col_comment] [<span class="hljs-keyword">FIRST</span>|<span class="hljs-keyword">AFTER</span> column_name]<br></code></pre></td></tr></table></figure>

<h5 id="具体实例-2"><a href="#具体实例-2" class="headerlink" title="具体实例"></a>具体实例</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> student <span class="hljs-keyword">ADD</span> (age <span class="hljs-built_in">int</span>);<br></code></pre></td></tr></table></figure>

<h3 id="2-1-3-删除表"><a href="#2-1-3-删除表" class="headerlink" title="2.1.3 删除表"></a>2.1.3 删除表</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">hive&gt; <span class="hljs-keyword">DROP</span> <span class="hljs-keyword">TABLE</span> test1;<br>OK<br><span class="hljs-type">Time</span> taken: <span class="hljs-number">0.191</span> seconds<br></code></pre></td></tr></table></figure>

<h3 id="2-1-4-数据库相关"><a href="#2-1-4-数据库相关" class="headerlink" title="2.1.4 数据库相关"></a>2.1.4 数据库相关</h3><p>创建数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">database</span>  [<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">exists</span>]   dbName  [location  <span class="hljs-keyword">path</span>];<br><br>示例：<br>    <span class="hljs-keyword">create</span> <span class="hljs-keyword">database</span> db1;  //    /user/hive/warehouse/<br>    <span class="hljs-keyword">create</span> <span class="hljs-keyword">database</span> db1;//报错 <br>    <span class="hljs-keyword">create</span> <span class="hljs-keyword">database</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">exists</span> db1;<br><br>    <span class="hljs-keyword">create</span> <span class="hljs-keyword">database</span>  db2 location <span class="hljs-string">'/user/db2.db'</span>;<br></code></pre></td></tr></table></figure>

<p>查看数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql">使用某一个数据库：<span class="hljs-keyword">use</span> databaseName;<br>查看所有的数据库：<span class="hljs-keyword">show</span> <span class="hljs-keyword">databases</span>;<br>查看某一个数据库的详细信息：desc database [extended]  dbName<br></code></pre></td></tr></table></figure>

<p>修改数据库</p>
<p>只能修改数据库的描述信息</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">database</span>  dbName  <span class="hljs-keyword">set</span> dbproperties(<span class="hljs-string">'desc'</span>=<span class="hljs-string">'ceshi db'</span>);<br></code></pre></td></tr></table></figure>

<p>删除数据库</p>
<figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs n1ql"><span class="hljs-keyword">drop</span> <span class="hljs-keyword">database</span> [<span class="hljs-keyword">if</span> <span class="hljs-keyword">exists</span>] dbName<br></code></pre></td></tr></table></figure>

<h3 id="2-1-4-显示命令"><a href="#2-1-4-显示命令" class="headerlink" title="2.1.4 显示命令"></a>2.1.4 显示命令</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">show</span> <span class="hljs-keyword">tables</span>;  <span class="hljs-comment"># 查看当前库中的所有的表</span><br><span class="hljs-keyword">show</span> <span class="hljs-keyword">tables</span> <span class="hljs-keyword">like</span> <span class="hljs-string">'*name*'</span>; <span class="hljs-comment"># hive模糊搜索表</span><br><span class="hljs-keyword">show</span> <span class="hljs-keyword">tables</span> <span class="hljs-keyword">in</span> dbName;     <span class="hljs-comment"># 指定查看某一个数据库中的所有的表</span><br><span class="hljs-keyword">show</span> <span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> tbName;  <span class="hljs-comment"># 查看某一个表的具体的建表语句（获取当前表设置的分隔符信息）</span><br><span class="hljs-keyword">show</span> <span class="hljs-keyword">databases</span><br><span class="hljs-keyword">show</span> <span class="hljs-keyword">partitions</span><br><span class="hljs-keyword">show</span> functions<br><span class="hljs-keyword">show</span> <span class="hljs-keyword">partitions</span> table_name; <span class="hljs-comment"># 查看分区信息</span><br><br>desc tbName; 查看表中的具体的字段信息<br>desc extended tbName ; 查看表的详情 （查看外部表）<br>desc formatted tbName ; 查看表的详情 （查看内部表和外部表）<br></code></pre></td></tr></table></figure>

<h2 id="2-2-DML操作"><a href="#2-2-DML操作" class="headerlink" title="2.2 DML操作"></a>2.2 DML操作</h2><h3 id="2-2-1-加载"><a href="#2-2-1-加载" class="headerlink" title="2.2.1 加载"></a>2.2.1 加载</h3><p>语法结构</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">LOAD</span> <span class="hljs-keyword">DATA</span> [<span class="hljs-keyword">LOCAL</span>] INPATH <span class="hljs-string">'filepath'</span> [OVERWRITE] <span class="hljs-keyword">INTO</span> <span class="hljs-keyword">TABLE</span> tablename [<span class="hljs-keyword">PARTITION</span> (partcol1=val1, partcol2=val2 ...)]<br></code></pre></td></tr></table></figure>

<p>说明：</p>
<ol>
<li><p>Load 操作只是单纯的复制&#x2F;移动操作，将数据文件移动到 Hive 表对应的位置。</p>
</li>
<li><p>filepath：</p>
</li>
</ol>
<ul>
<li>相对路径，例如：project&#x2F;data1</li>
<li>绝对路径，例如：&#x2F;user&#x2F;hive&#x2F;project&#x2F;data1</li>
<li>包含模式的完整 URI，列如：hdfs:&#x2F;&#x2F;namenode:9000&#x2F;user&#x2F;hive&#x2F;project&#x2F;data1</li>
</ul>
<ol start="3">
<li>LOCAL关键字</li>
</ol>
<p>  如果指定了 LOCAL， load 命令会去查找本地文件系统中的 filepath。<br>  如果没有指定 LOCAL 关键字，则根据inpath中的uri查找文件</p>
<ol start="4">
<li>OVERWRITE 关键字</li>
</ol>
<p>  如果使用了 OVERWRITE 关键字，则目标表（或者分区）中的内容会被删除，然后再将 filepath 指向的文件&#x2F;目录中的内容添加到表&#x2F;分区中。<br>  如果目标表（分区）已经有一个文件，并且文件名和 filepath 中的文件名冲突，那么现有的文件会被新文件所替代。</p>
<p> 具体实例</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"># 加载相对路径数据。<br>  hive&gt; <span class="hljs-keyword">load</span> data <span class="hljs-keyword">local</span> inpath <span class="hljs-string">'sc.txt'</span> overwrite <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> sc;  <br><br># 加载绝对路径数据。OVERWRITE关键字使用<br> hive&gt; <span class="hljs-keyword">load</span> data <span class="hljs-keyword">local</span> inpath <span class="hljs-string">'/home/hadoop/hivedata/students.txt'</span> overwrite <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> student;<br><br># 加载包含模式数据。OVERWRITE关键字使用<br> hive&gt; <span class="hljs-keyword">load</span> data inpath <span class="hljs-string">'hdfs://mini1:9000/hivedata/course.txt'</span> overwrite <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> course;<br></code></pre></td></tr></table></figure>

<h3 id="2-2-2-Insert"><a href="#2-2-2-Insert" class="headerlink" title="2.2.2 Insert"></a>2.2.2 Insert</h3><p> 将查询结果插入Hive表</p>
<p>语法结构</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 基本模式插入</span><br>INSERT OVERWRITE TABLE tablename1 [PARTITION (<span class="hljs-attribute">partcol1</span>=val1, <span class="hljs-attribute">partcol2</span>=val2 <span class="hljs-built_in">..</span>.)] select_statement1 <span class="hljs-keyword">FROM</span> from_statement<br><br><br><span class="hljs-comment"># 多插入模式 Multiple inserts:</span><br><br><span class="hljs-keyword">FROM</span> from_statement<br><br>INSERT OVERWRITE TABLE tablename1 [PARTITION (<span class="hljs-attribute">partcol1</span>=val1, <span class="hljs-attribute">partcol2</span>=val2 <span class="hljs-built_in">..</span>.)] select_statement1<br><br>[INSERT OVERWRITE TABLE tablename2 [PARTITION <span class="hljs-built_in">..</span>.] select_statement2] <span class="hljs-built_in">..</span>.<br><br><span class="hljs-comment"># 自动分区模式Dynamic partition inserts:</span><br><br>INSERT OVERWRITE TABLE tablename PARTITION (partcol1[=val1], partcol2[=val2] <span class="hljs-built_in">..</span>.) select_statement <span class="hljs-keyword">FROM</span> from_statement<br></code></pre></td></tr></table></figure>

<p>具体实例</p>
<p>1、导出文件到本地。</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">hive&gt; <span class="hljs-keyword">insert</span> overwrite <span class="hljs-keyword">local</span> directory <span class="hljs-string">'/home/hadoop/hivedata/outdata'</span>  <br>   &gt; <span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> student;<br></code></pre></td></tr></table></figure>

<p>说明：</p>
<p><em>数据写入到文件系统时进行文本序列化，且每列用^A来区分，\n为换行符。用more命令查看时不容易看出分割符，</em></p>
<p><em>可以使用: sed -e ‘s&#x2F;\x01&#x2F;|&#x2F;g’ filename来查看。</em></p>
<p>如：sed -e ‘s&#x2F;\x01&#x2F;,&#x2F;g’ 000000_0</p>
<p>2、导出数据到HDFS。</p>
<figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs n1ql">hive&gt; <span class="hljs-keyword">insert</span> overwrite directory <span class="hljs-string">'hdfs://mini1:9000/hivedata/outdatasc'</span>  <br>   &gt; <span class="hljs-keyword">select</span> \* <span class="hljs-keyword">from</span> sc;<br></code></pre></td></tr></table></figure>

<h3 id="2-2-3-SELECT"><a href="#2-2-3-SELECT" class="headerlink" title="2.2.3 SELECT"></a>2.2.3 SELECT</h3><p>基本的Select操作</p>
<p>语法结构</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> [<span class="hljs-keyword">ALL</span> | <span class="hljs-keyword">DISTINCT</span>] select_expr, select_expr, ...<br><span class="hljs-keyword">FROM</span> table_reference<br>[<span class="hljs-keyword">WHERE</span> where_condition]<br>[<span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> col_list [<span class="hljs-keyword">HAVING</span> condition]]<br>[CLUSTER <span class="hljs-keyword">BY</span> col_list<br>  | [<span class="hljs-keyword">DISTRIBUTE</span> <span class="hljs-keyword">BY</span> col_list] [<span class="hljs-keyword">SORT</span> <span class="hljs-keyword">BY</span>| <span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> col_list]<br>]<br>[<span class="hljs-keyword">LIMIT</span> <span class="hljs-built_in">number</span>]<br></code></pre></td></tr></table></figure>
<ol>
<li><p>order by 会对输入做全局排序，因此只有一个reducer，会导致当输入规模较大时，需要较长的计算时间。</p>
</li>
<li><p>sort by不是全局排序，其在数据进入reducer前完成排序。因此，如果用sort by进行排序，并且设置mapred.reduce.tasks&gt;1，则sort by只保证每个reducer的输出有序，不保证全局有序。</p>
</li>
<li><p>distribute by根据distribute by指定的内容将数据分到同一个reducer。</p>
</li>
<li><p>Cluster by 除了具有Distribute by的功能外，还会对该字段进行排序。因此，常常认为cluster by &#x3D; distribute by + sort by</p>
</li>
</ol>
<p>具体实例</p>
<figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs n1ql"># 1、获取年龄大的3个学生。<br>hive&gt; <span class="hljs-keyword">select</span> sno,sname,sage <span class="hljs-keyword">from</span> student <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> sage <span class="hljs-keyword">desc</span> <span class="hljs-keyword">limit</span> <span class="hljs-number">3</span>;<br><br># 2、查询学生信息按年龄，降序排序。<br>hive&gt; <span class="hljs-keyword">select</span> sno,sname,sage <span class="hljs-keyword">from</span> student sort <span class="hljs-keyword">by</span> sage <span class="hljs-keyword">desc</span>;<br>hive&gt; <span class="hljs-keyword">select</span> sno,sname,sage <span class="hljs-keyword">from</span> student <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> sage <span class="hljs-keyword">desc</span>;  <br>hive&gt; <span class="hljs-keyword">select</span> sno,sname,sage <span class="hljs-keyword">from</span> student distribute <span class="hljs-keyword">by</span> sage;  <br><br># 3、按学生名称汇总学生年龄。<br>hive&gt; <span class="hljs-keyword">select</span> sname,<span class="hljs-built_in">sum</span>(sage) <span class="hljs-keyword">from</span> student <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> sname;<br></code></pre></td></tr></table></figure>

<h2 id="2-3-Hive-Join"><a href="#2-3-Hive-Join" class="headerlink" title="2.3 Hive Join"></a>2.3 Hive Join</h2><p>语法结构</p>
<figure class="highlight vbscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs vbscript">join_table:<br><br>  table_reference <span class="hljs-built_in">JOIN</span> table_factor [join_condition]<br><br>  | table_reference &#123;<span class="hljs-built_in">LEFT</span>|<span class="hljs-built_in">RIGHT</span>|FULL&#125; [OUTER] <span class="hljs-built_in">JOIN</span> table_reference join_condition<br><br>  | table_reference <span class="hljs-built_in">LEFT</span> SEMI <span class="hljs-built_in">JOIN</span> table_reference join_condition<br></code></pre></td></tr></table></figure>

<p>Hive 支持等值连接（equality joins）、外连接（outer joins）和（left&#x2F;right joins）。Hive <strong>不支持非等值的连接（后续版本已经支持）</strong>，因为非等值连接非常难转化到 map&#x2F;reduce 任务。</p>
<p>另外，Hive 支持多于 2 个表的连接。</p>
<p>写 join 查询时，需要注意几个关键点：</p>
<ol>
<li>只支持等值join</li>
</ol>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment"># 正确的</span><br><span class="hljs-keyword">SELECT</span> a.* <span class="hljs-keyword">FROM</span> a <span class="hljs-keyword">JOIN</span> b <span class="hljs-keyword">ON</span> (a.id = b.id)<br><span class="hljs-keyword">SELECT</span> a.* <span class="hljs-keyword">FROM</span> a <span class="hljs-keyword">JOIN</span> b <span class="hljs-keyword">ON</span> (a.id = b.id <span class="hljs-keyword">AND</span> a.department = b.department)<br><br><span class="hljs-comment"># 错误的</span><br>  <span class="hljs-keyword">SELECT</span> a.* <span class="hljs-keyword">FROM</span> a <span class="hljs-keyword">JOIN</span> b <span class="hljs-keyword">ON</span> (a.id&gt;b.id)<br></code></pre></td></tr></table></figure>
<p>  tips:后续版本已经可以支持不等值</p>
<ol start="2">
<li>可以 join 多于 2 个表。</li>
</ol>
  <figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs n1ql"><span class="hljs-keyword">SELECT</span> a.val, b.val, c.val <span class="hljs-keyword">FROM</span> a <span class="hljs-keyword">JOIN</span> b <span class="hljs-keyword">ON</span> (a.<span class="hljs-keyword">key</span> = b.key1) <span class="hljs-keyword">JOIN</span> c <span class="hljs-keyword">ON</span> (c.<span class="hljs-keyword">key</span> = b.key2)<br><br># 如果<span class="hljs-keyword">join</span>中多个表的 <span class="hljs-keyword">join</span> <span class="hljs-keyword">key</span> 是同一个，则 <span class="hljs-keyword">join</span> 会被转化为单个 <span class="hljs-keyword">map</span>/<span class="hljs-keyword">reduce</span> 任务，例如：<br><br><span class="hljs-keyword">SELECT</span> a.val, b.val, c.val <span class="hljs-keyword">FROM</span> a <span class="hljs-keyword">JOIN</span> b<br><span class="hljs-keyword">ON</span> (a.<span class="hljs-keyword">key</span> = b.key1) <span class="hljs-keyword">JOIN</span> c<br><span class="hljs-keyword">ON</span> (c.<span class="hljs-keyword">key</span> = b.key1)<br><br># 被转化为单个 <span class="hljs-keyword">map</span>/<span class="hljs-keyword">reduce</span> 任务，因为 <span class="hljs-keyword">join</span> 中只使用了 b.key1 作为 <span class="hljs-keyword">join</span> <span class="hljs-keyword">key</span>。<br><br><span class="hljs-keyword">SELECT</span> a.val, b.val, c.val <span class="hljs-keyword">FROM</span> a <span class="hljs-keyword">JOIN</span> b <br><span class="hljs-keyword">ON</span> (a.<span class="hljs-keyword">key</span> = b.key1)<br><span class="hljs-keyword">JOIN</span> c <span class="hljs-keyword">ON</span> (c.<span class="hljs-keyword">key</span> = b.key2)<br><br># 而这一 <span class="hljs-keyword">join</span> 被转化为 <span class="hljs-number">2</span> 个 <span class="hljs-keyword">map</span>/<span class="hljs-keyword">reduce</span> 任务。因为 b.key1 用于第一次 <span class="hljs-keyword">join</span> 条件，而 b.key2 用于第二次 <span class="hljs-keyword">join</span>。<br></code></pre></td></tr></table></figure>

<ol start="3">
<li>join 时，每次 map&#x2F;reduce 任务的逻辑：</li>
</ol>
<p>  reducer 会缓存 join 序列中除了最后一个表的所有表的记录，再通过最后一个表将结果序列化到文件系统。这一实现有助于在 reduce 端减少内存的使用量。实践中，应该把最大的那个表写在最后（否则会因为缓存浪费大量内存）。例如：<br>  <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">SELECT <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.val</span>, <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.val</span>, c<span class="hljs-selector-class">.val</span> FROM a<br>JOIN <span class="hljs-selector-tag">b</span> ON (<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.key</span> = <span class="hljs-selector-tag">b</span>.key1) JOIN c ON (c<span class="hljs-selector-class">.key</span> = <span class="hljs-selector-tag">b</span>.key1)<br></code></pre></td></tr></table></figure><br>  所有表都使用同一个 join key（使用 1 次 map&#x2F;reduce 任务计算）。Reduce 端会缓存 a 表和 b 表的记录，然后每次取得一个 c 表的记录就计算一次 join 结果，类似的还有：<br>  <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">SELECT <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.val</span>, <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.val</span>, c<span class="hljs-selector-class">.val</span> FROM a<br>JOIN <span class="hljs-selector-tag">b</span> ON (<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.key</span> = <span class="hljs-selector-tag">b</span>.key1) JOIN c ON (c<span class="hljs-selector-class">.key</span> = <span class="hljs-selector-tag">b</span>.key2)<br></code></pre></td></tr></table></figure><br>  这里用了 2 次 map&#x2F;reduce 任务。第一次缓存 a 表，用 b 表序列化；第二次缓存第一次 map&#x2F;reduce 任务的结果，然后用 c 表序列化。</p>
<ol start="4">
<li>LEFT，RIGHT 和 FULL OUTER 关键字用于处理 join 中空记录的情况</li>
</ol>
  <figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs n1ql"><span class="hljs-keyword">SELECT</span> a.val, b.val <span class="hljs-keyword">FROM</span> a <span class="hljs-keyword">LEFT</span> <span class="hljs-keyword">OUTER</span> <span class="hljs-keyword">JOIN</span> b <span class="hljs-keyword">ON</span> (a.<span class="hljs-keyword">key</span>=b.<span class="hljs-keyword">key</span>)<br></code></pre></td></tr></table></figure>
<p>  对应所有 a 表中的记录都有一条记录输出。输出的结果应该是 a.val, b.val，当 a.key&#x3D;b.key 时，而当 b.key 中找不到等值的 a.key 记录时也会输出:a.val, NULL所以 a 表中的所有记录都被保留了；</p>
<p>  “a RIGHT OUTER JOIN b”会保留所有 b 表的记录。</p>
<p>  Join 发生在 WHERE 子句之前。如果你想限制 join 的输出，应该在 WHERE 子句中写过滤条件——或是在 join 子句中写。这里面一个容易混淆的问题是表分区的情况：</p>
  <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">SELECT <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.val</span>, <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.val</span> FROM a<br>LEFT OUTER JOIN <span class="hljs-selector-tag">b</span> ON (<span class="hljs-selector-tag">a</span>.key=<span class="hljs-selector-tag">b</span>.key)<br>WHERE <span class="hljs-selector-tag">a</span>.ds=<span class="hljs-string">'2009-07-07'</span> AND <span class="hljs-selector-tag">b</span>.ds=<span class="hljs-string">'2009-07-07'</span><br></code></pre></td></tr></table></figure>
<p>  会 join a 表到 b 表（OUTER JOIN），列出 a.val 和 b.val 的记录。WHERE 从句中可以使用其他列作为过滤条件。但是，如前所述，如果 b 表中找不到对应 a 表的记录，b 表的所有列都会列出 NULL，<strong>包括 ds 列</strong>。也就是说，join 会过滤 b 表中不能找到匹配 a 表 join key 的所有记录。这样的话，LEFT OUTER 就使得查询结果与 WHERE 子句无关了。解决的办法是在 OUTER JOIN 时使用以下语法：</p>
  <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">SELECT <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.val</span>, <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.val</span> FROM <span class="hljs-selector-tag">a</span> LEFT OUTER JOIN b<br>ON (<span class="hljs-selector-tag">a</span>.key=<span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.key</span> AND <span class="hljs-selector-tag">b</span>.ds=<span class="hljs-string">'2009-07-07'</span> AND <span class="hljs-selector-tag">a</span>.ds=<span class="hljs-string">'2009-07-07'</span>)<br></code></pre></td></tr></table></figure>
<p>  这一查询的结果是预先在 join 阶段过滤过的，所以不会存在上述问题。这一逻辑也可以应用于 RIGHT 和 FULL 类型的 join 中。</p>
<p>  Join 是不能交换位置的。无论是 LEFT 还是 RIGHT join，都是左连接的。</p>
  <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">SELECT <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.val1</span>, <span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.val2</span>, <span class="hljs-selector-tag">b</span><span class="hljs-selector-class">.val</span>, c.val<br>FROM a<br>JOIN <span class="hljs-selector-tag">b</span> ON (<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.key</span> = <span class="hljs-selector-tag">b</span>.key)<br>LEFT OUTER JOIN c ON (<span class="hljs-selector-tag">a</span><span class="hljs-selector-class">.key</span> = c.key)<br></code></pre></td></tr></table></figure>
<p>  先 join a 表到 b 表，丢弃掉所有 join key 中不匹配的记录，然后用这一中间结果和 c 表做 join。这一表述有一个不太明显的问题，就是当一个 key 在 a 表和 c 表都存在，但是 b 表中不存在的时候：整个记录在第一次 join，即 a JOIN b 的时候都被丢掉了（包括a.val1，a.val2和a.key），然后我们再和 c 表 join 的时候，如果 c.key 与 a.key 或 b.key 相等，就会得到这样的结果：NULL, NULL, NULL, c.val</p>
<p> 具体实例</p>
  <figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs n1ql">1、 查询选修了课程的学生姓名<br>hive&gt; <span class="hljs-keyword">select</span> <span class="hljs-keyword">distinct</span> Sname <span class="hljs-keyword">from</span> student <span class="hljs-keyword">inner</span> <span class="hljs-keyword">join</span> sc <span class="hljs-keyword">on</span> student.Sno=Sc.Sno;  <br>2.查询选修了3门以上的课程的学生学号  <br>hive&gt; <span class="hljs-keyword">select</span> Sno <span class="hljs-keyword">from</span> (<span class="hljs-keyword">select</span> Sno,<span class="hljs-built_in">count</span>(Cno) CountCno <span class="hljs-keyword">from</span> sc <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> Sno)a <span class="hljs-keyword">where</span> a.CountCno&gt;<span class="hljs-number">3</span>;<br></code></pre></td></tr></table></figure>

<h1 id="3-Hive-Shell参数"><a href="#3-Hive-Shell参数" class="headerlink" title="3 Hive Shell参数"></a>3 Hive Shell参数</h1><h2 id="3-1-Hive命令行"><a href="#3-1-Hive命令行" class="headerlink" title="3.1 Hive命令行"></a>3.1 Hive命令行</h2><p>语法结构</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs fsharp">hive [-hiveconf x=y]\* <span class="hljs-meta">[&lt;-i filename&gt;]</span>\* <span class="hljs-meta">[&lt;-f filename&gt;|&lt;-e query-string&gt;]</span> [-S]<br></code></pre></td></tr></table></figure>

<p>说明：</p>
<ol>
<li>-i 从文件初始化HQL。</li>
<li>-e从命令行执行指定的HQL</li>
<li>-f 执行HQL脚本</li>
<li>-v 输出执行的HQL语句到控制台</li>
<li>-p <port> connect to Hive Server on port number</li>
<li>-hiveconf x&#x3D;y Use this to set hive&#x2F;hadoop configuration variables.</li>
</ol>
<p>具体实例</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-number">1</span>、运行一个查询。<br> hive -e <span class="hljs-string">'select count(\*) from student'</span><br><br><span class="hljs-number">2</span>、运行一个文件。<br>hive -f hql.hql<br><br><span class="hljs-number">3</span>、运行参数文件。<br> hive -i initHQL.conf<br></code></pre></td></tr></table></figure>

<h2 id="3-2-Hive参数配置方式"><a href="#3-2-Hive参数配置方式" class="headerlink" title="3.2 Hive参数配置方式"></a>3.2 Hive参数配置方式</h2><p>Hive参数大全：<a href="https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties</a></p>
<p>开发Hive应用时，不可避免地需要设定Hive的参数。设定Hive的参数可以调优HQL代码的执行效率，或帮助定位问题。然而实践中经常遇到的一个问题是，为什么设定的参数没有起作用？这通常是错误的设定方式导致的。</p>
<p><strong>对于一般参数，有以下三种设定方式：</strong></p>
<p>1.)配置文件<br>2.)命令行参数<br>3.)参数声明 </p>
<p><strong>配置文件</strong>：Hive的配置文件包括</p>
<p>1.)用户自定义配置文件：$HIVE_CONF_DIR&#x2F;hive-site.xml<br>2.)默认配置文件：$HIVE_CONF_DIR&#x2F;hive-default.xml</p>
<p>用户自定义配置会覆盖默认配置。</p>
<p>另外，Hive也会读入Hadoop的配置，因为Hive是作为Hadoop的客户端启动的，Hive的配置会覆盖Hadoop的配置。</p>
<p>配置文件的设定对本机启动的所有Hive进程都有效。</p>
<p><strong>命令行参数</strong>：启动Hive（客户端或Server方式）时，可以在命令行添加-hiveconf param&#x3D;value来设定参数，例如：</p>
<p>bin&#x2F;hive -hiveconf hive.root.logger&#x3D;INFO,console</p>
<p>这一设定对本次启动的Session（对于Server方式启动，则是所有请求的Sessions）有效。</p>
<p><strong>参数声明</strong>：可以在HQL中使用SET关键字设定参数，例如：</p>
<p>set mapred.reduce.tasks&#x3D;100;</p>
<p>这一设定的作用域也是session级的。</p>
<p>上述三种设定方式的优先级依次递增。即参数声明覆盖命令行参数，命令行参数覆盖配置文件设定。注意某些系统级的参数，例如log4j相关的设定，必须用前两种方式设定，因为那些参数的读取在Session建立以前已经完成了。</p>
<h1 id="4-Hive函数"><a href="#4-Hive函数" class="headerlink" title="4 Hive函数"></a>4 Hive函数</h1><h2 id="4-1-内置运算符"><a href="#4-1-内置运算符" class="headerlink" title="4.1 内置运算符"></a>4.1 内置运算符</h2><p><em>内容较多，见《Hive官方文档》</em> </p>
<p><em><a href="http://hive.apache.org/" target="_blank" rel="noopener">http://hive.apache.org/</a></em></p>
<h2 id="4-2-内置函数"><a href="#4-2-内置函数" class="headerlink" title="4.2 内置函数"></a><strong>4.2 内置函数</strong></h2><p><em>内容较多，见《Hive官方文档》</em> </p>
<p><em><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF</a></em></p>
<h2 id="4-3-Hive自定义函数和Transform"><a href="#4-3-Hive自定义函数和Transform" class="headerlink" title="4.3 Hive自定义函数和Transform"></a><strong>4.3 Hive自定义函数和</strong>Transform</h2><p>当Hive提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined function）。</p>
<h3 id="4-3-1-自定义函数类别"><a href="#4-3-1-自定义函数类别" class="headerlink" title="4.3.1 自定义函数类别"></a><strong>4.3.1 自定义函数类别</strong></h3><p>UDF 作用于单个数据行，产生一个数据行作为输出。（数学函数，字符串函数）</p>
<p>UDAF（用户定义聚集函数）：接收多个输入数据行，并产生一个输出数据行。（count，max）</p>
<h3 id="4-3-2-UDF开发实例"><a href="#4-3-2-UDF开发实例" class="headerlink" title="4.3.2 UDF开发实例"></a><strong>4.3.2 UDF开发实例</strong></h3><p>1、先开发一个java类，继承UDF，并重载evaluate方法</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">package</span> cn.lyx.bigdata.udf<br><span class="hljs-keyword">import</span> org.apache.hadoop.hive.ql.exec.<span class="hljs-type">UDF</span>;<br><span class="hljs-keyword">import</span> org.apache.hadoop.io.<span class="hljs-type">Text</span>;<br><br><br>public <span class="hljs-keyword">final</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Lower</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">UDF</span></span>&#123;<br>    public <span class="hljs-type">Text</span> evaluate(<span class="hljs-keyword">final</span> <span class="hljs-type">Text</span> s)&#123;<br>        <span class="hljs-keyword">if</span>(s==<span class="hljs-literal">null</span>)&#123;<span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;&#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-type">Text</span>(s.toString().toLowerCase());<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>2、打成jar包上传到服务器</p>
<p>3、将jar包添加到hive的classpath</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">hive&gt;<span class="hljs-keyword">add</span><span class="bash"> JAR /home/hadoop/udf.jar;</span><br></code></pre></td></tr></table></figure>

<p>4、创建临时函数与开发好的java class关联</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">Hive&gt;<span class="hljs-keyword">create</span> <span class="hljs-keyword">temporary</span> <span class="hljs-keyword">function</span> toprovince <span class="hljs-keyword">as</span> <span class="hljs-string">'cn.lyx.bigdata.udf.ToProvince'</span>;<br></code></pre></td></tr></table></figure>

<p>5、即可在hql中使用自定义的函数strip </p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">Select</span> strip(<span class="hljs-type">name</span>),age <span class="hljs-keyword">from</span> t_test;<br></code></pre></td></tr></table></figure>

<h3 id="4-3-3-Transform实现"><a href="#4-3-3-Transform实现" class="headerlink" title="4.3.3 Transform实现"></a><strong>4.3.3 Transform实现</strong></h3><p>Hive的 TRANSFORM 关键字**<em>提供了在SQL中调用自写脚本的功能</em>**</p>
<p>适合实现Hive中没有的功能又不想写UDF的情况</p>
<p>使用示例1：下面这句sql就是借用了weekday_mapper.py对数据进行了处理.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> u_data_new (<br>  movieid <span class="hljs-built_in">INT</span>,<br>  rating <span class="hljs-built_in">INT</span>,<br>  <span class="hljs-keyword">weekday</span> <span class="hljs-built_in">INT</span>,<br>  userid <span class="hljs-built_in">INT</span>)<br><span class="hljs-keyword">ROW</span> <span class="hljs-keyword">FORMAT</span> <span class="hljs-keyword">DELIMITED</span><br><span class="hljs-keyword">FIELDS</span> <span class="hljs-keyword">TERMINATED</span> <span class="hljs-keyword">BY</span> <span class="hljs-string">'\t'</span>;<br>add FILE weekday_mapper.py;<br><span class="hljs-keyword">INSERT</span> OVERWRITE <span class="hljs-keyword">TABLE</span> u_data_new<br><span class="hljs-keyword">SELECT</span><br>  TRANSFORM (movieid, rating, unixtime,userid)<br>  <span class="hljs-keyword">USING</span> <span class="hljs-string">'python weekday_mapper.py'</span><br>  <span class="hljs-keyword">AS</span> (movieid, rating, <span class="hljs-keyword">weekday</span>,userid)<br><span class="hljs-keyword">FROM</span> u_data;<br></code></pre></td></tr></table></figure>

<p>其中weekday_mapper.py内容如下</p>
<figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs processing">#!/bin/python<br><br><span class="hljs-keyword">import</span> sys<br><br><span class="hljs-keyword">import</span> datetime<br><br><br><span class="hljs-keyword">for</span> <span class="hljs-built_in">line</span> in sys.stdin:<br>  <span class="hljs-built_in">line</span> = <span class="hljs-built_in">line</span>.strip()<br>  movieid, rating, unixtime,userid = <span class="hljs-built_in">line</span>.<span class="hljs-built_in">split</span>(<span class="hljs-string">'\t'</span>)<br>  weekday = datetime.datetime.fromtimestamp(<span class="hljs-built_in">float</span>(unixtime)).isoweekday()<br>  <span class="hljs-built_in">print</span> <span class="hljs-string">'\t'</span>.<span class="hljs-built_in">join</span>([movieid, rating, <span class="hljs-built_in">str</span>(weekday),userid])<br></code></pre></td></tr></table></figure>
<p>使用示例2：下面的例子则是使用了shell的cat命令来处理数据</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">FROM</span> invites a <span class="hljs-keyword">INSERT</span> OVERWRITE <span class="hljs-keyword">TABLE</span> events <span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">TRANSFORM</span>(a.foo, a.bar) <span class="hljs-keyword">AS</span> (oof, rab) <span class="hljs-keyword">USING</span> <span class="hljs-string">'/bin/cat'</span> <span class="hljs-keyword">WHERE</span> a.ds &amp;gt; <span class="hljs-string">'2008-08-08'</span>;<br></code></pre></td></tr></table></figure>

<p><a href="https://www.jianshu.com/p/6383611b308d" target="_blank" rel="noopener">https://www.jianshu.com/p/6383611b308d</a></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Hive/" class="category-chain-item">Hive</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Hive/" class="print-no-link">#Hive</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Hive 入门（old）</div>
      <div>https://flepeng.github.io/045-Hive-00-简介-Hive-入门（old）/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Lepeng</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年1月1日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/045-Hive-Hive3-%E6%96%B0%E7%89%B9%E6%80%A7/" title="Hive3 新特性">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Hive3 新特性</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/045-Hive-00-%E7%AE%80%E4%BB%8B-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%9F%BA%E7%A1%80/" title="数据仓库基础">
                        <span class="hidden-mobile">数据仓库基础</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
    <div id="giscus" class="giscus"></div>
    <script type="text/javascript">
      Fluid.utils.loadComments('#giscus', function() {
        var options = {"repo":"flepeng/hexo-blog-comment","repo-id":"R_kgDOL0qaig","category":"Announcements","category-id":"DIC_kwDOL0qais4CfBIv","theme-light":"light","theme-dark":"dark","mapping":"pathname","reactions-enabled":1,"emit-metadata":0,"input-position":"top","lang":"zh-CN"};
        var attributes = {};
        for (let option in options) {
          if (!option.startsWith('theme-')) {
            var key = option.startsWith('data-') ? option : 'data-' + option;
            attributes[key] = options[option];
          }
        }
        var light = 'light';
        var dark = 'dark';
        window.GiscusThemeLight = light;
        window.GiscusThemeDark = dark;
        attributes['data-theme'] = document.documentElement.getAttribute('data-user-color-scheme') === 'dark' ? dark : light;
        for (let attribute in attributes) {
          var value = attributes[attribute];
          if (value === undefined || value === null || value === '') {
            delete attributes[attribute];
          }
        }
        var s = document.createElement('script');
        s.setAttribute('src', 'https://giscus.app/client.js');
        s.setAttribute('crossorigin', 'anonymous');
        for (let attribute in attributes) {
          s.setAttribute(attribute, attributes[attribute]);
        }
        var ss = document.getElementsByTagName('script');
        var e = ss.length > 0 ? ss[ss.length - 1] : document.head || document.documentElement;
        e.parentNode.insertBefore(s, e.nextSibling);
      });
    </script>
    <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
